{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_version = 5\n",
    "codebook_version = 2\n",
    "output_version = 4\n",
    "\n",
    "output_flag = True\n",
    "verbose_flag = False # in-notebook outputs\n",
    "\n",
    "input_file = 'derived-dataframes/regression-data-v{}/codebook{}_longform.csv'.format(input_version, codebook_version)\n",
    "output_dir = 'output/figures-v{}'.format(output_version)\n",
    "\n",
    "if output_flag:\n",
    "    try:\n",
    "        os.mkdir(output_dir)\n",
    "    except FileExistsError:\n",
    "        print('High-level output directory already exists; no action taken.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use LaTeX for some plot title formatting\n",
    "# On my Ubuntu 20.04 system, my setup was:\n",
    "# apt install texlive-latex-extra texstudio dvipng ghostscript cm-super texlive-latex-extra texlive-fonts-recommended\n",
    "# pip install latex\n",
    "# Not necessary for the figures actually included in the paper (just skip those cells)\n",
    "supports_latex = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# util for displaying dataframes\n",
    "# the defaults are actually 60 & 20, but that gets annoying\n",
    "def show(da, rows = 20, cols = 20, width = None):\n",
    "    pd.set_option('display.max_rows', rows)\n",
    "    pd.set_option('display.max_columns', cols)\n",
    "    pd.set_option('display.max_colwidth', width)\n",
    "    display(da)\n",
    "    pd.reset_option('max_rows')\n",
    "    pd.reset_option('max_columns')\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1 = pd.read_csv(input_file, keep_default_na=False, na_values=['_'])\n",
    "if verbose_flag:\n",
    "    show(da1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1['code'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Get number of helpers\n",
    "Helpers must send at least one annotated message chunk (and have User ID > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hda = da1.copy()\n",
    "hda['contains non-greeting'] = ~hda['code'].str.contains('greeting')\n",
    "tmp = hda.groupby('document').aggregate(\n",
    "    {'annotator' : 'nunique'}).reset_index().rename(\n",
    "    columns={'annotator' : 'num annotators'})\n",
    "hda = pd.merge(left=hda, right=tmp, how='left', on='document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hda = hda.groupby(['document', 'speaker']).aggregate(\n",
    "    {'code' : ['count', 'nunique'], \n",
    "     'num annotators' : 'first', \n",
    "     'contains non-greeting' : 'any'} #, lambda s : s.str.endswith('greeting').any()\n",
    "    ).reset_index()\n",
    "hda = hda[hda['speaker'] > 0].reset_index(drop=True)\n",
    "hda.columns = hda.columns = [' '.join(col).strip() for col in hda.columns.values] # hda.columns.to_flat_index()\n",
    "hda = hda.rename(columns={'code count' : 'annotation count', \n",
    "                          'code nunique' : 'num unique codes', \n",
    "                          'num annotators first' : 'num annotators',\n",
    "                          'contains non-greeting any' : 'contains non-greeting'})\n",
    "hda['avg annotation count'] = hda['annotation count'] / hda['num annotators']\n",
    "hda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hda.hist('avg annotation count', bins=25, figsize=(10, 4))\n",
    "plt.axvline(hda['avg annotation count'].median(), ymin=0, ymax=1, color='yellow', linestyle='--', \n",
    "            label='Median = {:.2f}'.format(hda['avg annotation count'].median()))\n",
    "plt.axvline(hda['avg annotation count'].mean(), ymin=0, ymax=1, color='tab:orange', linestyle='--', \n",
    "            label='Mean = {:.2f}'.format(hda['avg annotation count'].mean()))\n",
    "plt.xlabel('Total number of message chunks sent (for the whole chat)')\n",
    "plt.ylabel('Number of helpers')\n",
    "plt.title('Total chat activity per helper, n={} (averaged across annotators)'.format(len(hda)))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('{} helpers sent at least 1 non-greeting message chunk'.format(\n",
    "    hda['contains non-greeting'].sum()))\n",
    "\n",
    "for t in [2, 3, 4, 5, 10]:\n",
    "    print('{} helpers sent at least {} message chunks'.format(\n",
    "        len(hda[hda['avg annotation count'] >= t]), t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "hda[~hda['contains non-greeting'] & hda['annotation count'] >= 10]\n",
    "if verbose_flag:\n",
    "    show(hda[~hda['contains non-greeting']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Double check data validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1['document'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(da1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data validity check\n",
    "print(tmp['num annotators'].value_counts()) # annotator count per document\n",
    "dd = tmp.loc[tmp['num annotators'] == 1, 'document'].to_list()\n",
    "da1[da1['document'].isin(dd)].groupby('document')['annotator'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Helping annotations:    ', (da1['code_primary'] == 'Helping').sum())\n",
    "print('Questioning annotations:', (da1['code_primary'] == 'Questioning').sum())\n",
    "print('Attitude annotations:   ', (da1['code_primary'].str.startswith('Attitude')).sum())\n",
    "print('Structural annotations: ', (da1['code_primary'].str.startswith('Big picture')).sum())\n",
    "# da1['code_primary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da1.loc[da1['code_primary'].str.startswith('Big picture of an interaction'), 'code'].value_counts()\n",
    "print('Requests:', da1['code_primary'].str.startswith('Big picture of an interaction > request').sum())\n",
    "print('Outcomes:', da1['code_primary'].str.startswith('Big picture of an interaction > resolveRequest').sum()) # ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Get request types by majority vote across annotators per interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1.groupby(by=['document', 'conversation_number']).aggregate({'voted_conversation_requests' : 'first'}).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Measure dissent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one entry per conversation-annotator\n",
    "da2_condensed = da1[da1['code'].str.startswith('Big picture of an interaction > resolveRequest')]\n",
    "da2_condensed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_agree = da2_condensed['conversation_requests'] == da2_condensed['voted_conversation_requests']\n",
    "requests_agree.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2_condensed.loc[~requests_agree]['voted_conversation_requests'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = da2_condensed.loc[~requests_agree]['voted_conversation_requests'].tolist()\n",
    "b = da2_condensed.loc[~requests_agree]['conversation_requests'].tolist()\n",
    "vals, counts = np.unique(list(zip(a, b)), return_counts=True, axis=0)\n",
    "\n",
    "print('MAJORITY         CLAIMED                         NO. INSTANCES')\n",
    "for i in range(len(vals)):\n",
    "    maj = vals[i][0]\n",
    "    cla = vals[i][1]\n",
    "    print(maj, ' ' * (15 - len(maj)), cla, ' ' * (30 - len(cla)), counts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Get outcomes by majority vote across annotators per interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1.groupby(by=['document', 'conversation_number']).aggregate({'voted_conversation_outcome' : 'first'}).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Measure dissent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_agree = da2_condensed['conversation_outcome'] == da2_condensed['voted_conversation_outcome']\n",
    "outcomes_agree.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2_condensed.loc[~outcomes_agree]['voted_conversation_outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = da2_condensed.loc[~outcomes_agree]['voted_conversation_outcome'].tolist()\n",
    "b = da2_condensed.loc[~outcomes_agree]['conversation_outcome'].tolist()\n",
    "c = da2_condensed.loc[~outcomes_agree]['voted_conversation_requests'].tolist()\n",
    "vals, counts = np.unique(list(zip(a, b, c)), return_counts=True, axis=0)\n",
    "\n",
    "print('REQUESTS              MAJORITY    CLAIMED     NO. INSTANCES')\n",
    "for i in range(len(vals)):\n",
    "    maj = vals[i][0]\n",
    "    cla = vals[i][1]\n",
    "    req = vals[i][2]\n",
    "    print(req, ' ' * (20 - len(req)), maj, ' ' * (10 - len(maj)), cla, ' ' * (10 - len(cla)), counts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interestingly, most disagreement on outcome occurs in codeWrite requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Get outcomes per request type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "convda = da1.groupby(by=['document', 'conversation_number'])\n",
    "convda = convda.aggregate({'voted_conversation_requests' : 'first', \n",
    "                           'voted_conversation_outcome' : 'first'})\n",
    "if verbose_flag:\n",
    "    show(convda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "convda['success'] = convda['voted_conversation_outcome'] == 'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_outcomes_da = convda.groupby(by=['voted_conversation_requests']).aggregate({'success' : ['sum', 'count']})\n",
    "request_outcomes_da[('success', 'rate')] = request_outcomes_da[('success', 'sum')] / request_outcomes_da[('success', 'count')]\n",
    "request_outcomes_da.sort_values(('success', 'count'), ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## Content domain frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should eventually move into the data preprocessing script\n",
    "if codebook_version == 1:\n",
    "    da1['code_contentDomain'] = np.where(da1['code'].str.startswith('General message attributes > contentDomain'), \n",
    "                                         da1['code'].str.split(' > ').str[2], \n",
    "                                         'N/A')\n",
    "\n",
    "# get the relevant rows\n",
    "conda = da1[da1['code_contentDomain'] != 'N/A'].copy()\n",
    "\n",
    "# shorten some variable names to make the labels on the graph a little easier to look at\n",
    "if codebook_version in {1, 2, 3}:\n",
    "    conda['code_contentDomain'] = conda['code_contentDomain'].replace(\n",
    "        {'proposedNewCode' : 'newCode', \n",
    "         'codeSpecifications' : 'specifications'}) \n",
    "if codebook_version in {4}:\n",
    "    conda['code_contentDomain'] = conda['code_contentDomain'].replace(\n",
    "        {'higherLevelInstruction' : 'holisticHelp', \n",
    "         'rapportBuilding' : 'rapport', \n",
    "         'codeSpecifications' : 'specifications'})\n",
    "\n",
    "# compute the thing\n",
    "def tmp(da):\n",
    "    da = da['code_contentDomain'].value_counts()\n",
    "    for c in conda['code_contentDomain'].unique():\n",
    "        if not c in da.index:\n",
    "            da[c] = 0\n",
    "    return da.sort_index()\n",
    "\n",
    "print(conda['code_contentDomain'].value_counts())\n",
    "\n",
    "confr = conda.groupby(by='annotator').apply(tmp)\n",
    "confr = confr.median(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "plt.bar(confr.index, confr)\n",
    "fl, ft, fa = 18, 20, 20\n",
    "plt.xlabel('Content domain', fontsize=fa)\n",
    "plt.ylabel('Number of instances', fontsize=fa)\n",
    "plt.title('Content domain frequencies across all data', fontsize=ft)\n",
    "plt.xticks(rotation=50, ha='right', fontsize=fl)\n",
    "fig.show()\n",
    "if output_flag:\n",
    "    fig.savefig(os.path.join(output_dir, 'content-counts.png'), bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Do it again but per-request-type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "#### Show them individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "confr = conda.groupby(by=['voted_conversation_requests', 'annotator']).apply(tmp)\n",
    "confr = confr.groupby(by='voted_conversation_requests').aggregate('median')\n",
    "confr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for request in confr.index:\n",
    "    fr = confr.loc[request].sort_values(ascending=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    plt.bar(fr.index, fr)\n",
    "    fl, ft, fa = 18, 20, 20\n",
    "    plt.xlabel('Content domain', fontsize=fa)\n",
    "    plt.ylabel('Number of instances', fontsize=fa)\n",
    "    plt.title('Content domain frequencies for request type {}'.format(request), fontsize=ft)\n",
    "    plt.xticks(rotation=50, ha='right', fontsize=fl)\n",
    "    if verbose_flag:\n",
    "        fig.show()\n",
    "    if output_flag:\n",
    "        fig.savefig(os.path.join(output_dir, '{}-content-counts.png'.format(request)), bbox_inches = 'tight')\n",
    "    if not verbose_flag:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "#### Show them all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_domain_names = {\n",
    "    'bug' : 'bug', \n",
    "    'codeOpinion' : 'code opinion', \n",
    "    'codingConcept' : 'coding concept', \n",
    "    'codingExperience': 'coding experience', \n",
    "    'developmentStrategy': 'development strategy', \n",
    "    'errorLocation': 'error location', \n",
    "    'errorMsg': 'error message', \n",
    "    'learningResources': 'learning resources', \n",
    "    'newCode': 'proposed new code', \n",
    "    'originalCode': 'original code', \n",
    "    'personalInfo': 'personal information', \n",
    "    'platformRelated': 'platform related', \n",
    "    'specifications': 'specifications', \n",
    "    'testCases': 'test cases'}\n",
    "\n",
    "request_names = {\n",
    "    'bugFix' : 'bug fixing', \n",
    "    'codeComprehension' : 'code comprehension', \n",
    "    'codeImprove' : 'code improvement', \n",
    "    'codeWrite' : 'code writing'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "confrp = confr.div(confr.sum(axis=1), axis=0)\n",
    "confrp = confrp.rename(columns=content_domain_names)\n",
    "confrp = confrp.rename(index=request_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "confrp = confrp[confrp.sum().sort_values(ascending=False).index]\n",
    "confrp = confrp.transpose()\n",
    "confrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlen = len(confrp)\n",
    "ax = confrp.iloc[:xlen].plot(kind='bar', figsize=(12, 4), width=0.8, zorder=3) # full-width version of Figure 4\n",
    "\n",
    "bars = ax.patches\n",
    "hatches = ''.join(h*xlen for h in 'xO/.')\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "ax.set_xlabel('\"Content Domain\"', fontsize=fa)\n",
    "ax.set_ylabel('Proportion of Instances', fontsize=fa)\n",
    "ax.set_title('\"Content Domain\" Frequencies Broken Down by \"Issue Request\"', fontsize=ft)\n",
    "ax.legend(fontsize=fl-2)\n",
    "plt.grid(zorder=0)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=fl-2)\n",
    "plt.yticks(fontsize=fl-2)\n",
    "if output_flag:\n",
    "    plt.savefig(os.path.join(output_dir, 'request-content-counts.png'), bbox_inches = 'tight')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlen = 5\n",
    "ax = confrp.iloc[:xlen].plot(kind='bar', figsize=(12, 4), width=0.8, zorder=3) # FIGURE 4\n",
    "\n",
    "bars = ax.patches\n",
    "hatches = ''.join(h*xlen for h in 'xO/.')\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "ax.set_xlabel('\"Content Domain\"', fontsize=fa)\n",
    "ax.set_ylabel('Proportion of Instances', fontsize=fa)\n",
    "ax.set_title('\"Content Domain\" Frequencies Broken Down by \"Issue Request\"', fontsize=ft)\n",
    "ax.legend(fontsize=fl-2)\n",
    "plt.grid(zorder=0)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=fl-2)\n",
    "plt.yticks(fontsize=fl-2)\n",
    "if output_flag:\n",
    "    plt.savefig(os.path.join(output_dir, 'request-content-counts.pdf'), bbox_inches = 'tight')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### Do it again but only for Learner questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(codebook_version in {2, 3, 4}) # need this structure for this to work\n",
    "\n",
    "qconda = conda[(conda['code_primary'] == 'Questioning') & conda['speakerIsLearner']] # & (conda['conversation_strict'] == True)\n",
    "qconfr = qconda.groupby(by=['document', 'conversation_number', 'voted_conversation_requests', 'annotator']).apply(tmp)\n",
    "qconfr = qconfr.groupby(by=['document', 'conversation_number', 'voted_conversation_requests']).aggregate('median')\n",
    "qconfr = qconfr.groupby(by='voted_conversation_requests').aggregate('sum')\n",
    "qconfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(codebook_version in {2, 3, 4})\n",
    "\n",
    "qconfrp = qconfr.div(qconfr.sum(axis=1), axis=0) # row-normalize\n",
    "# qconfrp = qconfrp[qconfr.sum(axis=0).sort_values(ascending=False).index] # by total counts\n",
    "qconfrp = qconfrp[qconfrp.sum(axis=0).sort_values(ascending=False).index] # by total proportions\n",
    "qconfrp = qconfrp.rename(index=request_names)\n",
    "qconfrp = qconfrp.rename(columns=content_domain_names, level=0)\n",
    "qconfrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(codebook_version in {2, 3, 4})\n",
    "\n",
    "if supports_latex:\n",
    "    mpl.rcParams['text.usetex'] = True\n",
    "\n",
    "ax = qconfrp.transpose().iloc[:6].plot(kind='bar', figsize=(12, 4), width=0.8)\n",
    "ax.set_ylabel('Proportion of Instances', fontsize=fa)\n",
    "if supports_latex:\n",
    "    x = '``Content Domain\"'\n",
    "    t = r'$\\textsc{Learner}$ ``Questioning\" $\\to$ ``Content Domain\" Frequencies Broken Down by ``Issue Request\"'\n",
    "else:\n",
    "    x = '\"Content Domain\"'\n",
    "    t = 'LEARNER \"Questioning\" > \"Content Domain\" Frequencies Broken Down by \"Issue Request\"'\n",
    "ax.set_xlabel(x, fontsize=fa)\n",
    "ax.set_title(t, fontsize=ft)\n",
    "ax.legend(fontsize=fl-2)\n",
    "plt.grid()\n",
    "plt.xticks(rotation=50, ha='right', fontsize=fl)\n",
    "if output_flag:\n",
    "    plt.savefig(os.path.join(output_dir, 'request-learner-question-content-counts.png'), bbox_inches = 'tight')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### Do it again but only for Helper explanations/help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(codebook_version in {2, 3, 4}) # need this structure for this to work\n",
    "\n",
    "hconda = conda[(conda['code_primary'] == 'Helping') & ~conda['speakerIsLearner']] # & (conda['conversation_strict'] == True)\n",
    "hconfr = hconda.groupby(by=['document', 'conversation_number', 'voted_conversation_requests', 'annotator']).apply(tmp)\n",
    "hconfr = hconfr.groupby(by=['document', 'conversation_number', 'voted_conversation_requests']).aggregate('median')\n",
    "hconfr = hconfr.groupby(by='voted_conversation_requests').aggregate('sum')\n",
    "hconfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(codebook_version in {2, 3, 4})\n",
    "\n",
    "hconfrp = hconfr.div(hconfr.sum(axis=1), axis=0) # row-normalize\n",
    "\n",
    "hconfrp = hconfrp[hconfrp.sum(axis=0).sort_values(ascending=False).index] # by total proportions\n",
    "hconfrp = hconfrp.rename(index=request_names)\n",
    "hconfrp = hconfrp.rename(columns=content_domain_names, level=0)\n",
    "# hconfrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(codebook_version in {2, 3, 4})\n",
    "\n",
    "if supports_latex:\n",
    "    mpl.rcParams['text.usetex'] = True\n",
    "\n",
    "ax = hconfrp.transpose().iloc[:6].plot(kind='bar', figsize=(12, 4), width=0.8)\n",
    "ax.set_ylabel('Proportion of Instances', fontsize=fa)\n",
    "# ax.set_title('Helping content frequencies broken down by request type', fontsize=ft)\n",
    "if supports_latex:\n",
    "    x = '``Content Domain\"'\n",
    "    t = r'$\\textsc{Helper}$ ``Helping\" $\\to$ ``Content Domain\" Frequencies Broken Down by ``Issue Request\"'\n",
    "else:\n",
    "    x = '\"Content Domain\"'\n",
    "    t = 'HELPER \"Helping\" > \"Content Domain\" Frequencies Broken Down by \"Issue Request\"'\n",
    "ax.set_xlabel(x, fontsize=fa)\n",
    "ax.set_title(t, fontsize=ft)\n",
    "ax.legend(fontsize=fl-2)\n",
    "plt.xticks(rotation=50, ha='right', fontsize=fl)\n",
    "plt.grid()\n",
    "if output_flag:\n",
    "    plt.savefig(os.path.join(output_dir, 'request-helper-helping-content-counts.png'), bbox_inches = 'tight')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "## Experience & personal info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "### Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "#### Coding experience\n",
    "\n",
    "This doesn't work for codebook 4, because it's been pooled with other things!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not codebook_version in {4})\n",
    "\n",
    "expda = da1[(da1['code_contentDomain'] == 'codingExperience') & da1['speakerIsLearner']]\n",
    "expda = expda.sort_values(['document', 'conversation_number', \n",
    "                           'quote_startPosition', 'quote_endPosition', 'annotator'])\n",
    "expda = expda[['document', 'conversation_number', 'annotator', 'quote_text', \n",
    "               'quote_startPosition', 'quote_endPosition']]\n",
    "\n",
    "if verbose_flag:\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    expda.groupby(by=['document']).apply(display)\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not codebook_version in {4})\n",
    "\n",
    "if verbose_flag:\n",
    "    # \"we saw everything in 1 week\"\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    display(da1[(da1['document'] == 'DRskphqiwF.txt') & \n",
    "                (da1['conversation_number'] == 0) & \n",
    "                (da1['annotator'] == 'A') &\n",
    "                (5200 < da1['quote_startPosition']) & \n",
    "                (da1['quote_startPosition'] < 5400)])\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not codebook_version in {4})\n",
    "\n",
    "if verbose_flag:\n",
    "    # \"yes, beginning though\"\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    display(da1[(da1['document'] == '6SdCx2rR9F.txt') & \n",
    "                (da1['conversation_number'] == 0) & \n",
    "                (3500 < da1['quote_startPosition']) & \n",
    "                (da1['quote_startPosition'] < 3707)])\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "#### Personal info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not codebook_version in {4})\n",
    "\n",
    "perda = da1[(da1['code_contentDomain'] == 'personalInfo') & da1['speakerIsLearner']]\n",
    "perda = perda.sort_values(['document', 'conversation_number', \n",
    "                           'quote_startPosition', 'quote_endPosition', 'annotator'])\n",
    "perda = perda[['document', 'conversation_number', 'annotator', 'quote_text', \n",
    "               'quote_startPosition', 'quote_endPosition']]\n",
    "\n",
    "if verbose_flag:\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    perda.groupby(by=['document']).apply(display)\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not codebook_version in {4})\n",
    "\n",
    "# nontraditional 1 (3 hr drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not codebook_version in {4})\n",
    "\n",
    "if verbose_flag:\n",
    "    # nontraditional 2 (Level 35)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    display(da1[(da1['document'] == '2I1pDSUuKI.txt') & \n",
    "                (da1['conversation_number'] == 0) & \n",
    "                (da1['annotator'] == 'A') & # output was too verbose\n",
    "                (4100 < da1['quote_startPosition']) & \n",
    "                (da1['quote_startPosition'] < 4616)])\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "#### Coding experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not codebook_version in {4})\n",
    "\n",
    "expda = da1[(da1['code_contentDomain'] == 'codingExperience') & ~da1['speakerIsLearner']]\n",
    "expda = expda.sort_values(['document', 'conversation_number', \n",
    "                           'quote_startPosition', 'quote_endPosition', 'annotator'])\n",
    "expda = expda[['document', 'conversation_number', 'annotator', 'quote_text', \n",
    "               'quote_startPosition', 'quote_endPosition']]\n",
    "\n",
    "if verbose_flag:\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    expda.groupby(by=['document']).apply(display)\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "#### Personal info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not codebook_version in {4})\n",
    "\n",
    "perda = da1[(da1['code_contentDomain'] == 'personalInfo') & ~da1['speakerIsLearner']]\n",
    "perda = perda.sort_values(['document', 'conversation_number', \n",
    "                           'quote_startPosition', 'quote_endPosition', 'annotator'])\n",
    "perda = perda[['document', 'conversation_number', 'annotator', 'quote_text', \n",
    "               'quote_startPosition', 'quote_endPosition']]\n",
    "\n",
    "if verbose_flag:\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    perda.groupby(by=['document']).apply(display)\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not codebook_version in {4})\n",
    "\n",
    "if verbose_flag:\n",
    "    # 'I am in 11th grade'\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    display(da1[(da1['document'] == 'nvPpBOafGk.txt') & \n",
    "                (da1['conversation_number'] == 0) & \n",
    "                (da1['annotator'] == 'A') & # output was too verbose\n",
    "                #(2900 < da1['quote_startPosition']) & \n",
    "                (da1['quote_startPosition'] < 3681)])\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "#### Teaching philosophy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "phida = da1[(da1['code'] == 'Attitude, tone, or mood > expressTeachingPhilosophy') & \n",
    "            ~da1['speakerIsLearner']]\n",
    "phida = phida.sort_values(['document', 'conversation_number', \n",
    "                           'quote_startPosition', 'quote_endPosition', 'annotator'])\n",
    "phida = phida[['document', 'conversation_number', 'annotator', 'quote_text', \n",
    "               'quote_startPosition', 'quote_endPosition']]\n",
    "\n",
    "if verbose_flag:\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    phida.groupby(by=['document']).apply(display)\n",
    "    pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "## Attitude/tone/mood frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "attitude_names = {\n",
    "    'greeting' : 'greeting', \n",
    "    'expressSupportingWords' : 'supporting words', \n",
    "    'expressSatisfactionOrGratitude' : 'gratitude', \n",
    "    'beingWrong' : 'being incorrect', \n",
    "    'apology' : 'apology', \n",
    "    'expressTeachingPhilosophy' : 'teaching philosophy', \n",
    "    'beingLost' : 'being lost', \n",
    "    'frustration' : 'frustration', \n",
    "    'selfTalk' : 'negative self-talk'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the relevant rows\n",
    "attda = da1[da1['code'].str.startswith('Attitude, tone, or mood')].copy()\n",
    "#attda['code'] = attda['code'].str[len('Attitude, tone, or mood > '):]\n",
    "attda['code'] = attda['code'].str.split(' > ').str[-1]\n",
    "\n",
    "# shorten some variable names to make the labels on the graph a little easier to look at\n",
    "attda['code'] = attda['code'].replace(attitude_names)\n",
    "print(len(attda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "attda['code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_names = ['greeting', 'supporting words', \n",
    "                  'gratitude', 'being incorrect', \n",
    "                  'apology', 'teaching philosophy', ]\n",
    "negative_names = ['being lost', 'frustration', 'negative self-talk']\n",
    "\n",
    "print('positive count', attda['code'].isin(positive_names).sum())\n",
    "print('negative count', attda['code'].isin(negative_names).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the thing\n",
    "def tmp(da):\n",
    "    da = da['code'].value_counts()\n",
    "    for c in attda['code'].unique():\n",
    "        if not c in da.index:\n",
    "            da[c] = 0\n",
    "    return da.sort_index()\n",
    "\n",
    "attfr = attda.groupby(by='annotator').apply(tmp)\n",
    "attfr = attfr.median(axis=0).sort_values(ascending=False)\n",
    "\n",
    "attfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is not particularly interesting imo\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "plt.bar(attfr.index, attfr)\n",
    "fl, ft, fa = 18, 20, 20\n",
    "plt.xlabel('Expression of Attitude, Tone, or Mood', fontsize=fa)\n",
    "plt.ylabel('Number of Instances', fontsize=fa)\n",
    "plt.title('\"Attitude\" Frequencies Across All Data', fontsize=ft)\n",
    "plt.xticks(rotation=50, ha='right', fontsize=fl)\n",
    "fig.show()\n",
    "if output_flag:\n",
    "    fig.savefig(os.path.join(output_dir, 'attitude-counts.png'), bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "attfr = attda.groupby(by=['voted_conversation_requests', 'annotator']).apply(tmp)\n",
    "attfr = attfr.groupby(by='voted_conversation_requests').aggregate('median')\n",
    "attfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for request in attfr.index:\n",
    "    fr = attfr.loc[request].sort_values(ascending=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    plt.bar(fr.index, fr)\n",
    "    fl, ft, fa = 18, 20, 20\n",
    "    plt.xlabel('Expression of attitude, tone, or mood', fontsize=fa)\n",
    "    plt.ylabel('Number of instances', fontsize=fa)\n",
    "    plt.title('Attitude/tone/mood frequencies for request type {}'.format(request), fontsize=ft)\n",
    "    plt.xticks(rotation=50, ha='right', fontsize=fl)\n",
    "    if verbose_flag:\n",
    "        fig.show()\n",
    "    if output_flag:\n",
    "        fig.savefig(os.path.join(output_dir, '{}-attitude-counts.png'.format(request)), bbox_inches = 'tight')\n",
    "    if not verbose_flag:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "attfrp = attfr.div(attfr.sum(axis=1), axis=0)\n",
    "# attfrp = attfrp.rename(columns={'apology' : 'Apology', \n",
    "#                                 'beingLost' : 'Being lost', \n",
    "#                                 'beingWrong' : 'Being wrong', \n",
    "#                                 'frustration' : 'Frustration', \n",
    "#                                 'greeting' : 'Greeting', \n",
    "#                                 'negativeSelfTalk' : 'Negative self talk', \n",
    "#                                 'satisfaction/gratitude' : 'Satisfaction or gratitude', \n",
    "#                                 'supportingWords' : 'Supporting words', \n",
    "#                                 'teachingPhilosophy' : 'Teaching philosophy'})\n",
    "attfrp = attfrp.rename(index=request_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "attfrp = attfrp[attfrp.sum().sort_values(ascending=False).index]\n",
    "attfrp = attfrp.transpose()\n",
    "attfrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = len(attfrp) #5\n",
    "ax = attfrp.iloc[:xlim].plot(kind='bar', figsize=(12, 4), width=0.8, zorder=3) # full-width version of Figure 5\n",
    "\n",
    "bars = ax.patches\n",
    "hatches = ''.join(h*xlim for h in 'xO/.')\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "ax.set_xlabel('\"Expression\"', fontsize=fa)\n",
    "ax.set_ylabel('Proportion of Instances', fontsize=fa)\n",
    "ax.set_title('\"Expression\" Frequencies Broken Down by \"Issue Request\"', fontsize=ft)\n",
    "ax.legend(fontsize=fl-2)\n",
    "plt.grid(zorder=0)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=fl-2)\n",
    "plt.yticks(fontsize=fl-2)\n",
    "if output_flag:\n",
    "    plt.savefig(os.path.join(output_dir, 'request-attitude-counts.png'), bbox_inches = 'tight')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = 5\n",
    "ax = attfrp.iloc[:xlim].plot(kind='bar', figsize=(12, 4), width=0.8, zorder=3) # FIGURE 5\n",
    "\n",
    "bars = ax.patches\n",
    "hatches = ''.join(h*xlim for h in 'xO/.')\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "ax.set_xlabel('\"Expression\"', fontsize=fa)\n",
    "ax.set_ylabel('Proportion of Instances', fontsize=fa)\n",
    "ax.set_title('\"Expression\" Frequencies Broken Down by \"Issue Request\"', fontsize=ft)\n",
    "ax.legend(fontsize=fl-2)\n",
    "plt.grid(zorder=0)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=fl-2)\n",
    "plt.yticks(fontsize=fl-2)\n",
    "if output_flag:\n",
    "    plt.savefig(os.path.join(output_dir, 'request-attitude-counts.pdf'), bbox_inches = 'tight')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "- It's worth noting that `codeComprehension` and `codeImprove` request types both suffer from small denominators\n",
    "- `greeting` is low for `codeComprehension` requests, potentially indicating that it's not usually the first request in a document\n",
    "- `greeting` is high for `codeImprove` requests, potentially indicating that it doesn't tend to stem from prior requests\n",
    "- `supportingWords` and `negativeSelfTalk` are both high for `codeComprehension` requests, potentially indicating that Learners find this more difficult than other request types\n",
    "- `supportingWords` is low for `codeImprove` requests, potentially indicating that Helpers perceive that Learners are struggling less or at a more advanced level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "### Taking a look at the conversation number hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "attfr = attda.groupby(by=['document', 'conversation_number', 'annotator']).apply(tmp)\n",
    "attfr = attfr.groupby(by=['document', 'conversation_number']).aggregate('median')\n",
    "attfr = attfr.groupby(by='conversation_number').aggregate('mean')\n",
    "attfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in attfr.index:\n",
    "    fr = attfr.loc[n]\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    plt.bar(fr.index, fr)\n",
    "    fl, ft, fa = 18, 20, 20\n",
    "    plt.xlabel('Expression of attitude, tone, or mood', fontsize=fa)\n",
    "    plt.ylabel('Average number of instances', fontsize=fa)\n",
    "    plt.title('Attitude/tone/mood frequencies for conversation {}'.format(n), fontsize=ft)\n",
    "    plt.xticks(rotation=50, ha='right', fontsize=fl)\n",
    "    if verbose_flag:\n",
    "        fig.show()\n",
    "    if output_flag:\n",
    "        fig.savefig(os.path.join(output_dir, 'conv{}-attitude-counts.png'.format(n)), bbox_inches = 'tight')\n",
    "    if not verbose_flag:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = attfr.transpose().plot(kind='bar', figsize=(12, 4), width=0.8)\n",
    "ax.set_xlabel('Expression of attitude, tone, or mood', fontsize=fa)\n",
    "ax.set_ylabel('Average number of instances', fontsize=fa)\n",
    "ax.set_title('Attitude/tone/mood frequencies broken down by conversation number', fontsize=ft)\n",
    "ax.legend(fontsize=fl-2)\n",
    "plt.xticks(rotation=50, ha='right', fontsize=fl)\n",
    "if output_flag:\n",
    "    plt.savefig(os.path.join(output_dir, 'conv-attitude-counts.png'), bbox_inches = 'tight')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "# Communication mechanism frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(codebook_version in {2})\n",
    "\n",
    "# get the relevant rows\n",
    "cmda = da1[da1['code_communicationMechanism'] != 'N/A'].copy()\n",
    "\n",
    "# shorten some variable names to make the labels on the graph a little easier to look at\n",
    "# if codebook_version in {2}:\n",
    "#     cmda['code_communicationMechanism'] = cmda['code_communicationMechanism'].replace(\n",
    "#         {'proposedNewCode' : 'newCode', \n",
    "#          'codeSpecifications' : 'specifications'}) \n",
    "\n",
    "# compute the thing\n",
    "def tmp(da):\n",
    "    da = da['code_communicationMechanism'].value_counts()\n",
    "    for c in cmda['code_communicationMechanism'].unique():\n",
    "        if not c in da.index:\n",
    "            da[c] = 0\n",
    "    return da.sort_index()\n",
    "\n",
    "cmfr = cmda.groupby(by='annotator').apply(tmp)\n",
    "cmfr = cmfr.median(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "plt.bar(cmfr.index, cmfr)\n",
    "fl, ft, fa = 18, 20, 20\n",
    "plt.xlabel('Communication mechanism', fontsize=fa)\n",
    "plt.ylabel('Number of instances', fontsize=fa)\n",
    "plt.title('Communication mechanism frequencies across all data', fontsize=ft)\n",
    "plt.xticks(rotation=50, ha='right', fontsize=fl)\n",
    "fig.show()\n",
    "# if output_flag:\n",
    "#     fig.savefig(os.path.join(output_dir, 'commMech-counts.png'), bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "## 5.2.3 Helper-specific strategies and varied participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_codes = [('code_communicationMechanism', 'guideInteractively'), \n",
    "                   ('code_communicationMechanism', 'teachWithExtensions'), \n",
    "                   ('code_questionType', 'guiding')]\n",
    "for col, val in candidate_codes:\n",
    "    print('{} > {}'.format(col, val))\n",
    "    tmp = da1.loc[da1[col] == val, 'speakerIsLearner'].value_counts()\n",
    "    L = tmp[True] if True in tmp.index else 0\n",
    "    H = tmp[False] if False in tmp.index else 0\n",
    "    print('\\tLearner: {} ({:.2f}%) \\tHelper: {} ({:.2f}%)'.format(\n",
    "        L, L/(L+H) * 100, \n",
    "        H, H/(L+H) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "attda['code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(attda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "attda.loc[attda['code'] == 'negative self-talk', 'speakerIsLearner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "attda.loc[attda['code'] == 'supporting words', 'speakerIsLearner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
