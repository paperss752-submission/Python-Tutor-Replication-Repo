{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Dataframe Preparation for Generalized Linear Regression Analysis of Annotated Chats\n",
    "\n",
    "Also low-rank SVD stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## README\n",
    "\n",
    "Section A of this document constructs long-form versions of the data under various codebooks:\n",
    "1. **Codebook 1**: The size-46 codebook consisting of all leaf nodes, with no programmatic incorporation of the multi-attribute structure for Helping and Questioning quotations that we enforced manually during the annotation phase.\n",
    "2. **Codebook 2**: The size-491 (or 897 with \"unknown\" attribute options) codebook in which every possible combination of attributes assigned to a Helping or Questioning instance is treated as an individual code (and attributes cannot occur outside of this structure). \\\n",
    "   \"Questioning\" : 5 \"goals/types\" $\\times$ 2 \"specificities\" $\\times$ 14 \"domains\" $=$ 140 \\\n",
    "   \"Helping\" (with \"specificity\") : 2 \"specificities\" $\\times$ 14 \"domains\" $\\times$ 2 \"confidences\" $\\times$ 4 \"mechanisms\" $=$ 224 \\\n",
    "   \"Helping\" (w/o \"specificity\") : 14 \"domains\" $\\times$ 2 \"confidences\" $\\times$ 4 \"mechanisms\" $=$ 112 \\\n",
    "   \"Attitude\" : 9 \"expressions\" \\\n",
    "   \"Issue Request\" : 4 \\\n",
    "   \"Issue Outcome\" : 2\n",
    "3. **Codebook 3**: The size-197 codebook constructed by dropping confidence and specificity information from Codebook 2.\n",
    "4. **Codebook 4**: The size-92 codebook derived from Codebook 3 via the following steps: \\\n",
    "   a) Merge \"guiding\" questions into \"guide interactively\" help \\\n",
    "   b) Merge positive and negative confirmation into \"confirmation\" \\\n",
    "   c) Group contentDomains per the [hierarchy](https://docs.google.com/drawings/d/1eRZkenY8Cjp6fhtUu1s5BPP2iBadhnJMK6h0sR8U31s/edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from scipy.stats.distributions import norm\n",
    "import statistics\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_version = 9\n",
    "input_file = \"../data-management/output/clean/v{}/annotations_data.csv\".format(input_version)\n",
    "document_metadata_file = \"../data-management/data/annotation-timeline.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = True\n",
    "output_version = 6\n",
    "\n",
    "outputdir = \"derived-dataframes/regression-data-v{}\".format(output_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Names of files that dataframes are output to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long-form dataframe of annotations with Primary Codebook\n",
    "# Output from Section A.1\n",
    "codebook1_annotations_output = \"codebook1_longform.csv\"\n",
    "codebook1_codes_output = \"codebook1_codes.csv\" # not using this atm because it's easy to get\n",
    "\n",
    "# Long-form dataframe of annotations with Questioning/Helping Codebook\n",
    "# Output from Section A.2\n",
    "codebook2_annotations_output = \"codebook2_longform.csv\"\n",
    "codebook2_codes_output = \"codebook2_codes.csv\"\n",
    "\n",
    "# Long-form dataframe of annotations with Questioning/Helping minus details Codebook\n",
    "# Output from Section A.3\n",
    "codebook3_annotations_output = \"codebook3_longform.csv\"\n",
    "codebook3_codes_output = \"codebook3_codes.csv\"\n",
    "\n",
    "# Long-form dataframe of annotations with Questioning/Helping grouping attributes Codebook\n",
    "# Output from Section A.4\n",
    "codebook4_annotations_output = \"codebook4_longform.csv\"\n",
    "codebook4_codes_output = \"codebook4_codes.csv\"\n",
    "\n",
    "# Pooled 1-gram counts dataframe, where each row is a code-outcome with its corresponding\n",
    "# number of observations\n",
    "# Output from Section B.1 (the actual outputs are prefixed with the codebook version)\n",
    "code_counts_output = \"code-outcome_counts.csv\"\n",
    "\n",
    "# 1-gram counts dataframe, where each row is a conversation-annotator-code-speaker with\n",
    "# its corresponding outcome and number of observations\n",
    "# Output from Section B.2 (the actual outputs are prefixed with the codebook version)\n",
    "conversation_1gram_counts_output = \"conv-annotator-code-speaker_outcome-counts.csv.gz\"\n",
    "\n",
    "# 1-gram counts dataframe, where each row is a conversation-annotator and each column\n",
    "# is a code-speaker (elements are counts)\n",
    "# Output from Section B.3 (the actual outputs are prefixed with the codebook version)\n",
    "countsmtx_output = \"conv-annotator_code-speaker_counts.csv\"\n",
    "\n",
    "# 2-gram counts dataframe, where each row is a conversation-annotator-code1-speaker1-code2-speaker2\n",
    "# with its corresponding outcome and number of observations\n",
    "# Output from Section C.1\n",
    "conversation_2gram_counts_output = \"conv-annotator-code2-speaker2_outcome-counts.csv.gz\"\n",
    "\n",
    "# the above dataframe is massive (>3 million rows) and doesn't display in github, so we'll also make a 20-line preview\n",
    "# Output from Section C.1\n",
    "small_conversation_2gram_counts_output = \"small_\" + conversation_2gram_counts_output[:-3]\n",
    "\n",
    "if output:\n",
    "    try:\n",
    "        os.mkdir(outputdir)\n",
    "    except FileExistsError:\n",
    "        print(\"Output directory already exists; no action taken.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Utility to change the pandas dataframe display settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option(\"display.max_colwidth\", None)\n",
    "#pd.reset_option(\"display.max_colwidth\")\n",
    "\n",
    "# util for displaying dataframes\n",
    "# the defaults are actually 60 & 20, but that gets annoying\n",
    "def show(da, rows = 20, cols = 20, width = None):\n",
    "    pd.set_option(\"display.max_rows\", rows)\n",
    "    pd.set_option(\"display.max_columns\", cols)\n",
    "    pd.set_option(\"display.max_colwidth\", width)\n",
    "    display(da)\n",
    "    pd.reset_option(\"max_rows\")\n",
    "    pd.reset_option(\"max_columns\")\n",
    "    pd.reset_option(\"display.max_colwidth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Read in the data\n",
    "First read in the main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "da0 = pd.read_csv(input_file, index_col=0, keep_default_na=False)\n",
    "da0 = da0.drop([\"da1.idx\", \"da2.idx\"], axis=1)\n",
    "da0.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "da0[\"document.creationDateTime\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## A. Long-form dataframe manipulation\n",
    "\n",
    "Produces the following dataframes:\n",
    "1. Copy of the input dataframe \\\n",
    "   Codebook size = 46\n",
    "\n",
    "2. Join the co-located Questioning (question, contentDomain, & specificity) and Helping (communicationMechanism, contentDomain, certainty, & specificity) annotations into a single \"Questioning\" or \"Helping\" annotation (still containing all the auxiliary information) \\\n",
    "   Codebook size = 897\n",
    "\n",
    "3. Join the co-located Questioning and Helping annotations like above, but drop less-interesting auxiliary information \\\n",
    "   Codebook size = ~197\n",
    "\n",
    "4. Further coarsening based on the hierarchy \\\n",
    "   Codebook size = 92"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### 0. Define utilities for column renaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The variable naming here is not ideal for use in R and regression analysis (e.g. column names are too long, \"interaction\" means two things, etc.)\n",
    "\n",
    "We will rename before outputting, but leave the names as-is in this script for legacy reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "da0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "da0.loc[da0['annotation.code'].str.contains('apology'), 'annotation.code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "da0.loc[da0['annotation.code'].str.contains('Doubt'), 'annotation.code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the renaming maps\n",
    "colname_map = {\"annotation.code\" : \"code\", \n",
    "               \"annotation.creatingUser\" : \"annotator\", \n",
    "               \"document.name\" : \"document\", \n",
    "               \"quote.speaker\" : \"speaker\", \n",
    "               \"quote.speakerIsLearner\" : \"speakerIsLearner\", \n",
    "               \"annotation.code.noOutcome\" : \"code.noOutcome\", \n",
    "               \"annotation.code.noRequestOutcome\" : \"code.noRequestOutcome\"}\n",
    "\n",
    "colterm_map = {\".\" : \"_\", \"interaction\" : \"conversation\"}\n",
    "\n",
    "def replace_colterms(colname, colterm_map = colterm_map):\n",
    "    for old, new in colterm_map.items():\n",
    "        colname = colname.replace(old, new)\n",
    "    return colname\n",
    "\n",
    "def output_longform(da, dirname, fname, colname_map = colname_map, colterm_map = colterm_map):\n",
    "    # real one\n",
    "    da.rename(columns={old : new for old, new in colname_map.items() if old in da.columns}\n",
    "          ).rename(columns={col : replace_colterms(col) for col in da.columns}\n",
    "                  ).to_csv(os.path.join(dirname, fname), index=False)\n",
    "    # mini one for previewing\n",
    "    da.rename(columns={old : new for old, new in colname_map.items() if old in da.columns}\n",
    "          ).rename(columns={col : replace_colterms(col) for col in da.columns}\n",
    "                  ).head(30).to_csv(os.path.join(dirname, \"small_\" + fname), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 1. Construct the first codebook & dataframe (`da1`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "The main thing we need to do here is \"take votes\" on request type and outcome for each interaction.\n",
    "\n",
    "Note that some annotators voted twice in some interactions (by assigning multiple request codes) -- these do count as two votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the end sentinels because there's exactly one per conversation-annotator (verified in csv cleaning script)\n",
    "votesda = da0[da0[\"annotation.code\"].str.startswith(\"Big picture of an interaction > resolveRequest\")]\n",
    "\n",
    "# take the vote (mode) across annotators for each conversation\n",
    "reqcol = votesda.groupby(by=[\"document.name\", \"interaction.number\"]).aggregate({\"interaction.requests\" : statistics.mode})\n",
    "\n",
    "# rename for later\n",
    "reqcol = reqcol.rename(columns={\"interaction.requests\" : \"voted.interaction.requests\"})\n",
    "reqcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the vote (mode) across annotators for each conversation\n",
    "outcol = votesda.groupby(by=[\"document.name\", \"interaction.number\"]).aggregate({\"interaction.outcome\" : statistics.mode})\n",
    "\n",
    "# rename for later\n",
    "outcol = outcol.rename(columns={\"interaction.outcome\" : \"voted.interaction.outcome\"})\n",
    "outcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1 = pd.merge(da0, reqcol, how=\"left\", on=[\"document.name\", \"interaction.number\"])\n",
    "da1 = pd.merge(da1, outcol, how=\"left\", on=[\"document.name\", \"interaction.number\"])\n",
    "da1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### Generate the codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_codes = np.sort(da1[\"annotation.code\"].unique()).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    #da1.rename(columns={old : new for old, new in colname_map.items() if old in da1.columns}\n",
    "    #          ).rename(columns={col : replace_colterms(col) for col in da1.columns}\n",
    "    #                  ).to_csv(os.path.join(outputdir, annotations_output), index=False)\n",
    "    output_longform(da1, outputdir, codebook1_annotations_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 2. Construct the second codebook & dataframe (`da2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that these output the same thing, so quote GUIDs are unique the way I want them\n",
    "#da1.groupby(by=\"quote.guid\").count()[\"da2.idx\"].value_counts()\n",
    "da1.groupby(by=[\"document.name\", \"annotation.creatingUser\", \"quote.guid\"]).count()[\"quote.text\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the result dataframe\n",
    "da2 = da1.copy()\n",
    "#da2[\"annotation.mainCodebook.code\"] = da2[\"annotation.code\"] # rows will change so this is useless\n",
    "\n",
    "# drop columns that won't be well-defined anymore\n",
    "da2 = da2.drop([\"annotation.creationDateTime\", \"annotation.guid\", \n",
    "                \"annotation.codeRef.guid\", \"annotation.original_code\"], \n",
    "               axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "#### a. Define utility functions for dealing with screwed up annotation clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function: given multiple contentDomains, choose the highest-priority\n",
    "# and breaking ties in favor of the less-frequent code\n",
    "contentDomainsByCount = da2.loc[da1[\"annotation.code\"].str.startswith(\"General message attributes > contentDomain\"), \n",
    "                                \"annotation.code\"].str.split(\" > \").str[-1].value_counts()\n",
    "contentDomainsByCount = contentDomainsByCount.sort_values(ascending=True).index.to_list()\n",
    "contentDomainsByCount = {i : k for k, i in enumerate(contentDomainsByCount)}\n",
    "#print(contentDomainsByCount)\n",
    "\n",
    "contentDomainPriorities = {\"bug\" : 0, \n",
    "                           \"codeSpecifications\" : 0, \n",
    "                           \"codingConcept\" : 0, \n",
    "                           \"learningResources\" : 0, \n",
    "                           \"developmentStrategy\" : 0, \n",
    "                           \"testCases\" : 0, \n",
    "                           \"codingExperience\" : 0, \n",
    "                           \"errorMsg\" : 1, \n",
    "                           \"errorLine\" : 2, \n",
    "                           \"errorLocation\" : 3, \n",
    "                           \"codeOpinion\" : 4, \n",
    "                           \"originalCode\" : 5, \n",
    "                           \"proposedNewCode\" : 5, \n",
    "                           \"platformRelated\" : 6} # FIXME this one is temporary\n",
    "\n",
    "def chooseContentDomain(ser):\n",
    "    if len(ser) == 1:\n",
    "        return ser.iloc[0].split(\" > \")[-1]\n",
    "    elif len(ser) == 0:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    ls = ser.str.split(\" > \").str[-1].to_list()\n",
    "    c0 = ls[0]\n",
    "    p0 = contentDomainPriorities[c0]\n",
    "    for c1 in ls[1:]:\n",
    "        p1 = contentDomainPriorities[c1]\n",
    "        if p0 < p1 or c0 == c1:\n",
    "            continue\n",
    "        elif p0 > p1:\n",
    "            c0, p0 = c1, p1\n",
    "        else: # p0 == p1\n",
    "            q0 = contentDomainsByCount[c0]\n",
    "            q1 = contentDomainsByCount[c1]\n",
    "            c0, p0 = (c0, p0) if q0 < q1 else (c1, p1)\n",
    "    return c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function: given multiple communicationMechanisms, choose the highest-priority\n",
    "# and breaking ties in favor of the less-frequent code\n",
    "commMechsByCount = da2.loc[da1[\"annotation.code\"].str.startswith(\"Explanations and help > communicationMechanism\"), \n",
    "                               \"annotation.code\"].str.split(\" > \").str[-1].value_counts()\n",
    "commMechsByCount = commMechsByCount.sort_values(ascending=True).index.to_list()\n",
    "commMechsByCount = {i : k for k, i in enumerate(commMechsByCount)}\n",
    "#print(commMechsByCount)\n",
    "\n",
    "commMechPriorities = {\"explain\" : 0, \n",
    "                      \"implement\" : 0, \n",
    "                      \"guideInteractively\" : 0, \n",
    "                      \"suggest\" : 1, \n",
    "                      \"teachWithExtensions\" : 2, \n",
    "                      \"state\" : 3, \n",
    "                      \"positiveConfirmation\" : 4, \n",
    "                      \"negativeConfirmation\" : 4}\n",
    "\n",
    "def chooseCommunicationMechanism(ser):\n",
    "    if len(ser) == 1:\n",
    "        return ser.iloc[0].split(\" > \")[-1]\n",
    "    elif len(ser) == 0:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    ls = ser.str.split(\" > \").str[-1].to_list()\n",
    "    c0 = ls[0]\n",
    "    p0 = commMechPriorities[c0]\n",
    "    for c1 in ls[1:]:\n",
    "        p1 = commMechPriorities[c1]\n",
    "        if p0 < p1 or c0 == c1:\n",
    "            continue\n",
    "        elif p0 > p1:\n",
    "            c0, p0 = c1, p1\n",
    "        else: # p0 == p1\n",
    "            q0 = commMechsByCount[c0]\n",
    "            q1 = commMechsByCount[c1]\n",
    "            c0, p0 = (c0, p0) if q0 < q1 else (c1, p1)\n",
    "    return c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one is totally unnecessary, but while we're over-engineering things, we might as well go all the way\n",
    "# checkForFollowing, guiding, personal, checkIfCorrect\n",
    "# content\n",
    "\n",
    "# utility function: given multiple question types, choose the highest-priority\n",
    "# and breaking ties in favor of the less-frequent code\n",
    "questionsByCount = da2.loc[da1[\"annotation.code\"].str.startswith(\"Questions > question\"), \n",
    "                               \"annotation.code\"].str.split(\" > \").str[-1].value_counts()\n",
    "questionsByCount = questionsByCount.sort_values(ascending=True).index.to_list()\n",
    "questionsByCount = {i : k for k, i in enumerate(questionsByCount)}\n",
    "print(questionsByCount)\n",
    "\n",
    "questionPriorities = {\"checkForFollowing\" : 0, \n",
    "                      \"guiding\" : 0, \n",
    "                      \"personal\" : 0, \n",
    "                      \"checkIfCorrect\" : 0, \n",
    "                      \"content\" : 1}\n",
    "\n",
    "def chooseQuestionType(ser):\n",
    "    if len(ser) == 1:\n",
    "        return ser.iloc[0].split(\" > \")[-1]\n",
    "    elif len(ser) == 0:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    ls = ser.str.split(\" > \").str[-1].to_list()\n",
    "    c0 = ls[0]\n",
    "    p0 = questionPriorities[c0]\n",
    "    for c1 in ls[1:]:\n",
    "        p1 = questionPriorities[c1]\n",
    "        if p0 < p1 or c0 == c1:\n",
    "            continue\n",
    "        elif p0 > p1:\n",
    "            c0, p0 = c1, p1\n",
    "        else: # p0 == p1\n",
    "            q0 = questionsByCount[c0]\n",
    "            q1 = questionsByCount[c1]\n",
    "            c0, p0 = (c0, p0) if q0 < q1 else (c1, p1)\n",
    "    return c0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### b. Extract the helping quotes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all quote GUIDs associated with \"Explanations & help\" via various criteria that \n",
    "# agree theoretically but probably not in practive\n",
    "\n",
    "# Helping instances and communicationMechanism annotations should correspond exactly\n",
    "help_quote_guid1 = np.sort(da1.loc[da1[\"annotation.code\"].str.startswith(\n",
    "    \"Explanations and help > communicationMechanism\"), \"quote.guid\"].unique())\n",
    "\n",
    "# Helping instances and confidenceLevel annotations should correspond exactly\n",
    "help_quote_guid2 = np.sort(da1.loc[da1[\"annotation.code\"].str.startswith(\n",
    "    \"Explanations and help > confidenceLevel\"), \"quote.guid\"].unique())\n",
    "\n",
    "# Helping instances should be a subset of contentDomain instances (Questioning\n",
    "# instances also have these)\n",
    "help_quote_guid3 = np.sort(da1.loc[da1[\"annotation.code\"].str.startswith(\n",
    "    \"General message attributes > contentDomain\"), \"quote.guid\"].unique())\n",
    "\n",
    "# [explain, suggest, guideinteractively, & teachW/extensions] Helping instances should \n",
    "# be a subset of specificity instances (Questioning instances also have these)\n",
    "help_quote_guid4 = np.sort(da1.loc[da1[\"annotation.code\"].str.startswith(\n",
    "    \"Questions > specificity\"), \"quote.guid\"].unique())\n",
    "\n",
    "len(help_quote_guid1), len(help_quote_guid2), len(help_quote_guid3), len(help_quote_guid4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out the communication mechanisms determining whether the Helping instance has 3 vs 4 attributes\n",
    "commMechs4 = [\"Explanations and help > communicationMechanism > explain\", \n",
    "              \"Explanations and help > communicationMechanism > suggest\", \n",
    "              \"Explanations and help > communicationMechanism > guideInteractively\", \n",
    "              \"Explanations and help > communicationMechanism > teachWithExtensions\"]\n",
    "\n",
    "# derive the complement\n",
    "commMechs3 = da1[\"annotation.code\"].unique()\n",
    "commMechs3 = commMechs3.astype(\"U\")\n",
    "commMechs3 = commMechs3[np.char.startswith(commMechs3, \"Explanations and help > communicationMechanism\")]\n",
    "commMechs3 = commMechs3.astype(\"object\")\n",
    "commMechs3 = np.delete(commMechs3, np.isin(commMechs3, commMechs4))\n",
    "commMechs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the corresponding quote GUIDs\n",
    "help_quote_guid5 = np.sort(da1.loc[da1[\"annotation.code\"].isin(commMechs3), \"quote.guid\"].unique())\n",
    "help_quote_guid6 = np.sort(da1.loc[da1[\"annotation.code\"].isin(commMechs4), \"quote.guid\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the shared part of the filter\n",
    "# 1. annotation belongs to a quote with a confidenceLevel annotation\n",
    "#    too many messages are missing these, so we'll deal with it later instead\n",
    "#help_filter = da1[\"quote.guid\"].isin(help_quote_guid2)\n",
    "\n",
    "# 2. annotation belongs to a quote with a contentDomain annotation\n",
    "help_filter = da1[\"quote.guid\"].isin(help_quote_guid3)\n",
    "\n",
    "#print(da1.loc[help_filter, \"annotation.code\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "##### (i) Helping quotes with 3 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the filter for Helping messages with 3 attributes\n",
    "\n",
    "# 3. annotation belongs to one of the three categories of attributes\n",
    "help3_filter = da1[\"annotation.code\"].str.startswith(\"Explanations and help > confidenceLevel\")\n",
    "help3_filter |= da1[\"annotation.code\"].str.startswith(\"General message attributes > contentDomain\")\n",
    "#help3_filter |= da1[\"annotation.code\"].str.startswith(\"Questions > specificity\")\n",
    "for commMech in commMechs3:\n",
    "    help3_filter |= (da1[\"annotation.code\"] == commMech)\n",
    "\n",
    "# 4. annotation belongs to a quote with a communicationMechanism annotation in the relevant category\n",
    "help3_filter &= help_filter & da1[\"quote.guid\"].isin(help_quote_guid5)\n",
    "help3_filter.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the results dataframe for this category\n",
    "da2_help3 = da2[help3_filter]\n",
    "\n",
    "da2_help3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2_help3.groupby(by=\"quote.guid\").count()[\"quote.text\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = da2_help3.groupby(by=\"quote.guid\")\n",
    "tmp = tmp.aggregate({\"quote.text\" : \"count\", \n",
    "                     \"document.name\" : \"first\", \n",
    "                     \"annotation.creatingUser\" : \"first\", \n",
    "                     \"annotation.code\" : \n",
    "                     [lambda ser : ser.str.startswith(\"Explanations and help > communicationMechanism\").sum(), \n",
    "                      lambda ser : ser.str.startswith(\"Explanations and help > confidenceLevel\").sum(), \n",
    "                      lambda ser : ser.str.startswith(\"General message attributes > contentDomain\").sum()]\n",
    "                    })\n",
    "tmp.columns = [\"count\", \"document.name\", \"annotation.creatingUser\", \"commMech.count\", \"conf.count\", \"content.count\"]\n",
    "tmp[\"dist\"] = list(zip(tmp[\"commMech.count\"].to_list(), tmp[\"conf.count\"].to_list(), tmp[\"content.count\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"dist\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show(tmp[tmp[\"count\"] != 3], cols=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Code to check the above annotations without exactly 3 attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_colwidth\", None)\n",
    "# display(da2_help3[da2_help3[\"quote.guid\"] == \"10B67B86-6785-471B-BD23-E62282DC1105\"])\n",
    "# pd.reset_option(\"display.max_colwidth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Construct the combined dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note this works because I've already verified that all invalid Helping quotes\n",
    "# have too many contentDomains XOR no confidenceLevel, and no other problems\n",
    "def combinecodes_help3(codeser):\n",
    "    commMechs = codeser[codeser.str.startswith(\"Explanations and help > communicationMechanism\")]\n",
    "    confLevels = codeser[codeser.str.startswith(\"Explanations and help > confidenceLevel\")].unique()\n",
    "    confLvl = confLevels[0].split(\" > \")[-1] if len(confLevels) == 1 else \"unknown\"\n",
    "    contentDomains = codeser[codeser.str.startswith(\"General message attributes > contentDomain\")]\n",
    "    return \"Helping > ({}, {}, {})\".format(chooseCommunicationMechanism(commMechs), \n",
    "                                           confLvl, \n",
    "                                           chooseContentDomain(contentDomains))\n",
    "\n",
    "agg_dict = {col : \"first\" for col in da2_help3.columns}\n",
    "agg_dict[\"annotation.code\"] = combinecodes_help3\n",
    "\n",
    "da2_help3 = da2_help3.groupby(by=\"quote.guid\").aggregate(agg_dict).reset_index(drop=True)\n",
    "show(da2_help3, cols=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2_help3[\"annotation.code\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with theoretical number of possibilities\n",
    "# (n commMechs3) * (n certainties + 1) * (n contentDomains)\n",
    "(4) * (2 + 1) * (14)\n",
    "#np.sort(da1[\"annotation.code\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rows describing the codes, broken down\n",
    "da2_help3[\"code.primary\"] = \"Helping\"\n",
    "\n",
    "da2_help3[\"code.communicationMechanism\"] = da2_help3[\"annotation.code\"].str.split(\" > \").str[1].str.split(\", \").str[0].str[1:]\n",
    "da2_help3[\"code.confidenceLevel\"] = da2_help3[\"annotation.code\"].str.split(\", \").str[1]\n",
    "da2_help3[\"code.contentDomain\"] = da2_help3[\"annotation.code\"].str.split(\", \").str[2].str[:-1]\n",
    "\n",
    "da2_help3[\"code.questionType\"] = \"N/A\"\n",
    "da2_help3[\"code.specificity\"] = \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "##### (iI) Helping quotes with 4 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the filter for Helping messages with 4 attributes\n",
    "\n",
    "# 3. annotation belongs to a quote with a communicationMechanism annotation in the relevant category\n",
    "help_filter &= da1[\"quote.guid\"].isin(help_quote_guid6)\n",
    "\n",
    "# 4. annotation belongs to a quote with a specificity instance\n",
    "#    too many messages are missing these, so we'll deal with it later instead\n",
    "#help_filter &= da1[\"quote.guid\"].isin(help_quote_guid4)\n",
    "\n",
    "# 5. annotation belongs to one of the four categories of attributes\n",
    "help4_filter = da1[\"annotation.code\"].str.startswith(\"Explanations and help > confidenceLevel\")\n",
    "help4_filter |= da1[\"annotation.code\"].str.startswith(\"General message attributes > contentDomain\")\n",
    "help4_filter |= da1[\"annotation.code\"].str.startswith(\"Questions > specificity\")\n",
    "for commMech in commMechs4:\n",
    "    help4_filter |= (da1[\"annotation.code\"] == commMech)\n",
    "\n",
    "help4_filter &= help_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the results dataframe for this category\n",
    "da2_help4 = da2[help4_filter]\n",
    "\n",
    "# keep track of the leftovers\n",
    "da2 = da2[~help3_filter & ~help4_filter]\n",
    "\n",
    "da2_help4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2_help4.groupby(by=\"quote.guid\").count()[\"quote.text\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = da2_help4.groupby(by=\"quote.guid\")\n",
    "tmp = tmp.aggregate({\"quote.text\" : \"count\", \n",
    "                     \"document.name\" : \"first\", \n",
    "                     \"annotation.creatingUser\" : \"first\", \n",
    "                     \"annotation.code\" : \n",
    "                     [lambda ser : ser.str.startswith(\"Explanations and help > communicationMechanism\").sum(), \n",
    "                      lambda ser : ser.str.startswith(\"Explanations and help > confidenceLevel\").sum(), \n",
    "                      lambda ser : ser.str.startswith(\"General message attributes > contentDomain\").sum(), \n",
    "                      lambda ser : ser.str.startswith(\"Questions > specificity\").sum()]\n",
    "                    })\n",
    "tmp.columns = [\"count\", \"document.name\", \"annotation.creatingUser\", \n",
    "               \"commMech.count\", \"conf.count\", \"content.count\", \"specificity.count\"]\n",
    "\n",
    "tmp[\"dist\"] = list(zip(tmp[\"commMech.count\"].to_list(), tmp[\"conf.count\"].to_list(), \n",
    "                       tmp[\"content.count\"].to_list(), tmp[\"specificity.count\"].to_list()))\n",
    "\n",
    "#tmp[tmp[\"count\"] != 4]\n",
    "tmp[\"dist\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "Code to check the above annotations without exactly one of each category of attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_colwidth\", None)\n",
    "# display(da2_help4[da2_help4[\"quote.guid\"] == \"027E3617-0493-423B-9819-3CE56C88DE99\"])\n",
    "# pd.reset_option(\"display.max_colwidth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinecodes_help4(codeser):\n",
    "    commMechs = codeser[codeser.str.startswith(\"Explanations and help > communicationMechanism\")]\n",
    "    confLevels = codeser[codeser.str.startswith(\"Explanations and help > confidenceLevel\")].unique()\n",
    "    confLvl = confLevels[0].split(\" > \")[-1] if len(confLevels) == 1 else \"unknown\"\n",
    "    contentDomains = codeser[codeser.str.startswith(\"General message attributes > contentDomain\")]\n",
    "    specificities = codeser[codeser.str.startswith(\"Questions > specificity\")].unique()\n",
    "    spec = specificities[0].split(\" > \")[-1] if len(specificities) == 1 else \"unknown\"\n",
    "    return \"Helping > ({}, {}, {}, {})\".format(chooseCommunicationMechanism(commMechs), \n",
    "                                               confLvl, \n",
    "                                               chooseContentDomain(contentDomains), \n",
    "                                               spec)\n",
    "\n",
    "agg_dict = {col : \"first\" for col in da2_help4.columns}\n",
    "agg_dict[\"annotation.code\"] = combinecodes_help4\n",
    "\n",
    "da2_help4 = da2_help4.groupby(by=\"quote.guid\").aggregate(agg_dict).reset_index(drop=True)\n",
    "show(da2_help4, cols=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2_help4[\"annotation.code\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with theoretical number of possibilities\n",
    "# (n commMechs4) * (n certainties + 1) * (n contentDomains) * (n specificities + 1)\n",
    "(4) * (2 + 1) * (14) * (2 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rows describing the codes, broken down\n",
    "\n",
    "da2_help4[\"code.primary\"] = \"Helping\"\n",
    "\n",
    "da2_help4[\"code.communicationMechanism\"] = da2_help4[\"annotation.code\"].str.split(\" > \").str[1].str.split(\", \").str[0].str[1:]\n",
    "da2_help4[\"code.confidenceLevel\"] = da2_help4[\"annotation.code\"].str.split(\", \").str[1]\n",
    "da2_help4[\"code.contentDomain\"] = da2_help4[\"annotation.code\"].str.split(\", \").str[2]\n",
    "da2_help4[\"code.specificity\"] = da2_help4[\"annotation.code\"].str.split(\", \").str[3].str[:-1]\n",
    "\n",
    "da2_help4[\"code.questionType\"] = \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "#### c. Extract the questioning quotes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all quote GUIDs associated with \"Questions\" via various criteria\n",
    "\n",
    "# Questioning instances and questions annotations should correspond exactly\n",
    "ques_quote_guid1 = np.sort(da2.loc[da2[\"annotation.code\"].str.startswith(\n",
    "    \"Questions > question\"), \"quote.guid\"].unique())\n",
    "\n",
    "# Questioning should be a subset of contentDomain annotations (Helping instances also have these)\n",
    "ques_quote_guid2 = np.sort(da2.loc[da2[\"annotation.code\"].str.startswith(\n",
    "    \"General message attributes > contentDomain\"), \"quote.guid\"].unique())\n",
    "\n",
    "# Questioning instances should be a subset of specificity annotations (Helping instances also have these)\n",
    "ques_quote_guid3 = np.sort(da2.loc[da2[\"annotation.code\"].str.startswith(\n",
    "    \"Questions > specificity\"), \"quote.guid\"].unique())\n",
    "\n",
    "len(ques_quote_guid1), len(ques_quote_guid2), len(ques_quote_guid3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the filter\n",
    "# 1. annotation belongs to a quote with a questions annotation\n",
    "ques_filter = da2[\"quote.guid\"].isin(ques_quote_guid1)\n",
    "\n",
    "# 2. annotation belongs to a quote with a contentDomain annotation\n",
    "ques_filter &= da2[\"quote.guid\"].isin(ques_quote_guid2)\n",
    "\n",
    "# 3. annotation belongs to a quote with a specificity annotation\n",
    "#    too many messages are missing these, so we'll deal with it later instead\n",
    "#ques_filter &= da2[\"quote.guid\"].isin(ques_quote_guid3)\n",
    "\n",
    "tmp = da2[\"annotation.code\"].str.startswith(\"Questions > question\")\n",
    "tmp |= da2[\"annotation.code\"].str.startswith(\"General message attributes > contentDomain\")\n",
    "tmp |= da2[\"annotation.code\"].str.startswith(\"Questions > specificity\")\n",
    "ques_filter &= tmp\n",
    "\n",
    "#print(da2.loc[ques_filter, \"annotation.code\"].value_counts().sort_index())\n",
    "ques_filter.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the results dataframe for this category\n",
    "da2_ques = da2[ques_filter]\n",
    "\n",
    "# keep track of the leftovers\n",
    "da2 = da2[~ques_filter]\n",
    "\n",
    "da2_ques.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2_ques.groupby(by=\"quote.guid\").count()[\"quote.text\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = da2_ques.groupby(by=\"quote.guid\")\n",
    "tmp = tmp.aggregate({\"quote.text\" : \"count\", \n",
    "                     \"document.name\" : \"first\", \n",
    "                     \"annotation.creatingUser\" : \"first\", \n",
    "                     \"annotation.code\" : \n",
    "                     [lambda ser : ser.str.startswith(\"Questions > question\").sum(), \n",
    "                      lambda ser : ser.str.startswith(\"General message attributes > contentDomain\").sum(), \n",
    "                      lambda ser : ser.str.startswith(\"Questions > specificity\").sum()]\n",
    "                    })\n",
    "tmp.columns = [\"count\", \"document.name\", \"annotation.creatingUser\", \n",
    "               \"quesType.count\", \"content.count\", \"specificity.count\"]\n",
    "\n",
    "tmp[\"dist\"] = list(zip(tmp[\"quesType.count\"].to_list(), \n",
    "                       tmp[\"content.count\"].to_list(), \n",
    "                       tmp[\"specificity.count\"].to_list()))\n",
    "\n",
    "tmp[\"dist\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinecodes_ques(codeser):\n",
    "    #if len(codeser) > 3:\n",
    "    #    contentDomains = codeser[codeser.str.startswith(\"General message attributes > contentDomain\")]\n",
    "    #    codeser = codeser[~codeser.str.startswith(\"General message attributes > contentDomain\")]\n",
    "    #    codeser[contentDomains.index[0]] = chooseContentDomain(contentDomains)\n",
    "    \n",
    "    #attr = \", \".join(codeser.sort_values().str.split(\" > \").str[-1])\n",
    "    #return \"Questioning > ({})\".format(attr)\n",
    "    \n",
    "    contentDomains = codeser[codeser.str.startswith(\"General message attributes > contentDomain\")]\n",
    "    specificities = codeser[codeser.str.startswith(\"Questions > specificity\")].unique()\n",
    "    spec = specificities[0].split(\" > \")[-1] if len(specificities) == 1 else \"unknown\"\n",
    "    questions = codeser[codeser.str.startswith(\"Questions > question\")]\n",
    "    return \"Questioning > ({}, {}, {})\".format(chooseContentDomain(contentDomains), \n",
    "                                               spec, \n",
    "                                               chooseQuestionType(questions))\n",
    "\n",
    "agg_dict = {col : \"first\" for col in da2_ques.columns}\n",
    "agg_dict[\"annotation.code\"] = combinecodes_ques\n",
    "\n",
    "da2_ques = da2_ques.groupby(by=\"quote.guid\").aggregate(agg_dict).reset_index(drop=True)\n",
    "show(da2_ques, cols=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rows describing the codes, broken down\n",
    "\n",
    "da2_ques[\"code.primary\"] = \"Questioning\"\n",
    "\n",
    "da2_ques[\"code.contentDomain\"] = da2_ques[\"annotation.code\"].str.split(\" > \").str[1].str.split(\", \").str[0].str[1:]\n",
    "da2_ques[\"code.specificity\"] = da2_ques[\"annotation.code\"].str.split(\", \").str[1]\n",
    "da2_ques[\"code.questionType\"] = da2_ques[\"annotation.code\"].str.split(\", \").str[2].str[:-1]\n",
    "\n",
    "da2_ques[\"code.communicationMechanism\"] = \"N/A\"\n",
    "da2_ques[\"code.confidenceLevel\"] = \"N/A\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "#### d. Join everybody back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a small number of miscellaneous Helping and Questioning attributes that were lying loose\n",
    "# around the dataset are going to be dropped, but that's okay -- let's check how many\n",
    "tmp = da2[da2[\"annotation.code\"].str.startswith(\"Explanations and help\") | \n",
    "          da2[\"annotation.code\"].str.startswith(\"General message attributes\") | \n",
    "          da2[\"annotation.code\"].str.startswith(\"Questions\")]\n",
    "print(len(tmp))\n",
    "tmp[\"annotation.code\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2_others = da2[~(da2[\"annotation.code\"].str.startswith(\"Explanations and help\") | \n",
    "                   da2[\"annotation.code\"].str.startswith(\"General message attributes\") | \n",
    "                   da2[\"annotation.code\"].str.startswith(\"Questions\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rows describing the codes, broken down\n",
    "\n",
    "da2_others[\"code.primary\"] = da2_others[\"annotation.code\"].copy()\n",
    "\n",
    "da2_others[\"code.communicationMechanism\"] = \"N/A\"\n",
    "da2_others[\"code.confidenceLevel\"] = \"N/A\"\n",
    "da2_others[\"code.contentDomain\"] = \"N/A\"\n",
    "da2_others[\"code.questionType\"] = \"N/A\"\n",
    "da2_others[\"code.specificity\"] = \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2 = pd.concat([da2_help3, da2_help4, da2_ques, da2_others], axis=0)\n",
    "da2 = da2.sort_values([\"document.name\", \"quote.startPosition\", \"quote.endPosition\", \"annotation.creatingUser\"])\n",
    "da2 = da2.reset_index(drop=True)\n",
    "assert(len(da2) == len(da2_help3) + len(da2_help4) + len(da2_ques) + len(da2_others))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "#### e. Do some postprocessing on masked code columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2[\"annotation.code.noOutcome\"] = np.where(da2[\"annotation.code\"].str.startswith(\"Helping > \") | \n",
    "                                            da2[\"annotation.code\"].str.startswith(\"Questioning > \"), \n",
    "                                            da2[\"annotation.code\"], da2[\"annotation.code.noOutcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2[\"annotation.code.noRequestOutcome\"] = np.where(da2[\"annotation.code\"].str.startswith(\"Helping > \") | \n",
    "                                                   da2[\"annotation.code\"].str.startswith(\"Questioning > \"), \n",
    "                                                   da2[\"annotation.code\"], da2[\"annotation.code.noRequestOutcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(da2, cols=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2[\"code.communicationMechanism\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2[\"code.confidenceLevel\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2[\"code.contentDomain\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2[\"code.specificity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "da2[\"code.questionType\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "#### f. Generate the codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "annser = pd.Series(np.sort(da1[\"annotation.code\"].unique()))\n",
    "short_commMechs3 = pd.Series(commMechs3).str.split(\" > \").str[-1].to_list()\n",
    "short_commMechs4 = pd.Series(commMechs4).str.split(\" > \").str[-1].to_list()\n",
    "confidenceLevels = annser[annser.str.startswith(\"Explanations and help > confidenceLevel\")].str.split(\" > \").str[-1].to_list() + [\"unknown\"]\n",
    "contentDomains = annser[annser.str.startswith(\"General message attributes > contentDomain\")].str.split(\" > \").str[-1].to_list()\n",
    "specificities = annser[annser.str.startswith(\"Questions > specificity\")].str.split(\" > \").str[-1].to_list() + [\"unknown\"]\n",
    "questionTypes = annser[annser.str.startswith(\"Questions > question\")].str.split(\" > \").str[-1].to_list()\n",
    "others = annser[~annser.str.startswith(\"Explanations and help\") & \n",
    "                ~annser.str.startswith(\"General message attributes > contentDomain\") & \n",
    "                ~annser.str.startswith(\"Questions\")].to_list()\n",
    "\n",
    "help3_codes = np.array(np.meshgrid(short_commMechs3, confidenceLevels, contentDomains), dtype=\"object\")\n",
    "help3_codes = help3_codes.T.reshape([-1, 3])\n",
    "help3_codes = list(map(lambda ls : \"Helping > ({})\".format(\", \".join(ls)), help3_codes))\n",
    "\n",
    "help4_codes = np.array(np.meshgrid(short_commMechs4, confidenceLevels, contentDomains, specificities), dtype=\"object\")\n",
    "help4_codes = help4_codes.T.reshape([-1, 4])\n",
    "help4_codes = list(map(lambda ls : \"Helping > ({})\".format(\", \".join(ls)), help4_codes))\n",
    "\n",
    "question_codes = np.array(np.meshgrid(contentDomains, specificities, questionTypes), dtype=\"object\")\n",
    "question_codes = question_codes.T.reshape([-1, 3])\n",
    "question_codes = list(map(lambda ls : \"Questioning > ({})\".format(\", \".join(ls)), question_codes))\n",
    "\n",
    "da2_codes = help3_codes + help4_codes + question_codes + others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(da2_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of codes if we didn't have \"unknown\" as an option\n",
    "(4 * 2 * 14) + (4 * 2 * 14 * 2) + (5 * 14 * 2) + len(others)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "#### g. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    output_longform(da2, outputdir, codebook2_annotations_output)\n",
    "    #da2.to_csv(os.path.join(outputdir, codebook2_annotations_output), index=False)\n",
    "    pd.Series(da2_codes).to_csv(os.path.join(outputdir, codebook2_codes_output), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "### 3. Construct the third codebook and dataframe (`da3`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "#### a. Regenerate the codes in the long-form dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "da3 = da2.copy()\n",
    "da3 = da3.drop([\"code.confidenceLevel\", \"code.specificity\"], axis=\"columns\")\n",
    "da3[\"annotation.code\"] = np.where(da3[\"code.primary\"] == \"Helping\", \n",
    "                                  np.frompyfunc(\"Helping > ({}, {})\".format, 2, 1)(\n",
    "                                      da3[\"code.communicationMechanism\"], da3[\"code.contentDomain\"]), \n",
    "                                  da3[\"annotation.code\"])\n",
    "da3[\"annotation.code\"] = np.where(da3[\"code.primary\"] == \"Questioning\", \n",
    "                                  np.frompyfunc(\"Questioning > ({}, {})\".format, 2, 1)(\n",
    "                                      da3[\"code.questionType\"], da3[\"code.contentDomain\"]), \n",
    "                                  da3[\"annotation.code\"])\n",
    "show(da3, cols=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "#### b. Do some postprocessing on masked code columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "da3[\"annotation.code.noOutcome\"] = np.where(da3[\"annotation.code\"].str.startswith(\"Helping > \") | \n",
    "                                            da3[\"annotation.code\"].str.startswith(\"Questioning > \"), \n",
    "                                            da3[\"annotation.code\"], da3[\"annotation.code.noOutcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "da3[\"annotation.code.noRequestOutcome\"] = np.where(da3[\"annotation.code\"].str.startswith(\"Helping > \") | \n",
    "                                                   da3[\"annotation.code\"].str.startswith(\"Questioning > \"), \n",
    "                                                   da3[\"annotation.code\"], da3[\"annotation.code.noRequestOutcome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "#### c. Generate the codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many codes were used\n",
    "da3[\"annotation.code\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the codebook size for comparison\n",
    "(4 * 14) + (4 * 14) + (5 * 14) + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "commMechs = annser[annser.str.startswith(\"Explanations and help > communicationMechanism\")].str.split(\" > \").str[-1].to_list()\n",
    "\n",
    "help_codes = np.array(np.meshgrid(commMechs, contentDomains), dtype=\"object\")\n",
    "help_codes = help_codes.T.reshape([-1, 2])\n",
    "help_codes = list(map(lambda ls : \"Helping > ({})\".format(\", \".join(ls)), help_codes))\n",
    "\n",
    "ques_codes = np.array(np.meshgrid(questionTypes, contentDomains), dtype=\"object\")\n",
    "ques_codes = ques_codes.T.reshape([-1, 2])\n",
    "ques_codes = list(map(lambda ls : \"Questioning > ({})\".format(\", \".join(ls)), ques_codes))\n",
    "\n",
    "da3_codes = help_codes + ques_codes + others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(da3_codes) # matches the hardcoded calculation, yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "#### d. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    output_longform(da3, outputdir, codebook3_annotations_output)\n",
    "    pd.Series(da3_codes).to_csv(os.path.join(outputdir, codebook3_codes_output), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "### 4. Construct the fourth codebook and dataframe (`da4`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "#### a. Do the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "da4 = da3.copy()\n",
    "\n",
    "# Merge guiding codes\n",
    "fil = da4[\"code.questionType\"] == \"guiding\"\n",
    "da4.loc[fil, \"code.primary\"] = \"Helping\"\n",
    "da4.loc[fil, \"code.questionType\"] = \"N/A\"\n",
    "da4.loc[fil, \"code.communicationMechanism\"] = \"guideInteractively\"\n",
    "da4[\"annotation.code\"] = np.where(fil, \n",
    "                                  np.frompyfunc(\"Helping > ({}, {})\".format, 2, 1)(\n",
    "                                      da4[\"code.communicationMechanism\"], da4[\"code.contentDomain\"]), \n",
    "                                  da4[\"annotation.code\"])\n",
    "\n",
    "# Merge confirmation codes\n",
    "fil = da4[\"code.communicationMechanism\"].str.endswith(\"confirmation\")\n",
    "da4.loc[fil, \"code.communicationMechanism\"] = \"confirmation\"\n",
    "da4[\"annotation.code\"] = np.where(fil, \n",
    "                                  np.frompyfunc(\"Helping > ({}, {})\".format, 2, 1)(\n",
    "                                      da4[\"code.communicationMechanism\"], da4[\"code.contentDomain\"]), \n",
    "                                  da4[\"annotation.code\"])\n",
    "\n",
    "# Merge contentDomain codes\n",
    "grp = {\"proposedNewCode\"     : \"sourceCode\", \n",
    "       \"originalCode\"        : \"sourceCode\", \n",
    "       \"codeOpinion\"         : \"sourceCode\", \n",
    "       \"bug\"                 : \"codeError\", \n",
    "       \"errorLocation\"       : \"codeError\", \n",
    "       \"errorMsg\"            : \"codeError\", \n",
    "       \"codingConcept\"       : \"higherLevelInstruction\", \n",
    "       \"developmentStrategy\" : \"higherLevelInstruction\", \n",
    "       \"learningResources\"   : \"higherLevelInstruction\", \n",
    "       \"codingExperience\"    : \"rapportBuilding\", \n",
    "       \"personalInfo\"        : \"rapportBuilding\"}\n",
    "fil = da4[\"code.contentDomain\"] != \"N/A\"\n",
    "da4[\"code.contentDomain\"] = np.frompyfunc(lambda c : grp[c] if c in grp.keys() else c, \n",
    "                                          1, 1)(da4[\"code.contentDomain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "da4[\"annotation.code\"] = np.where(da4[\"code.primary\"] == \"Helping\", \n",
    "                                  np.frompyfunc(\"Helping > ({}, {})\".format, 2, 1)(\n",
    "                                      da4[\"code.communicationMechanism\"], da4[\"code.contentDomain\"]), \n",
    "                                  da4[\"annotation.code\"])\n",
    "da4[\"annotation.code\"] = np.where(da4[\"code.primary\"] == \"Questioning\", \n",
    "                                  np.frompyfunc(\"Questioning > ({}, {})\".format, 2, 1)(\n",
    "                                      da4[\"code.questionType\"], da4[\"code.contentDomain\"]), \n",
    "                                  da4[\"annotation.code\"])\n",
    "show(da4, cols=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect 529 guideInteractively instances\n",
    "da4[\"code.communicationMechanism\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {},
   "source": [
    "#### b. Do some postprocessing on masked code columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "da4[\"annotation.code.noOutcome\"] = np.where(da4[\"annotation.code\"].str.startswith(\"Helping > \") | \n",
    "                                            da4[\"annotation.code\"].str.startswith(\"Questioning > \"), \n",
    "                                            da4[\"annotation.code\"], da4[\"annotation.code.noOutcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "da4[\"annotation.code.noRequestOutcome\"] = np.where(da4[\"annotation.code\"].str.startswith(\"Helping > \") | \n",
    "                                                   da4[\"annotation.code\"].str.startswith(\"Questioning > \"), \n",
    "                                                   da4[\"annotation.code\"], da4[\"annotation.code.noRequestOutcome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "#### c. Generate the codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many codes were used\n",
    "da4[\"annotation.code\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the codebook size for comparison\n",
    "(7 * 7) + (4 * 7) + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionTypes.remove(\"guiding\")\n",
    "\n",
    "commMechs.remove(\"positiveConfirmation\")\n",
    "commMechs.remove(\"negativeConfirmation\")\n",
    "commMechs.append(\"confirmation\")\n",
    "\n",
    "contentDomains = np.concatenate([[c for c in contentDomains if not c in grp.keys()], np.unique(list(grp.values()))])\n",
    "\n",
    "help_codes = np.array(np.meshgrid(commMechs, contentDomains), dtype=\"object\")\n",
    "help_codes = help_codes.T.reshape([-1, 2])\n",
    "help_codes = list(map(lambda ls : \"Helping > ({})\".format(\", \".join(ls)), help_codes))\n",
    "\n",
    "ques_codes = np.array(np.meshgrid(questionTypes, contentDomains), dtype=\"object\")\n",
    "ques_codes = ques_codes.T.reshape([-1, 2])\n",
    "ques_codes = list(map(lambda ls : \"Questioning > ({})\".format(\", \".join(ls)), ques_codes))\n",
    "\n",
    "da4_codes = help_codes + ques_codes + others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(da4_codes) # matches the hardcoded calculation, yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "#### d. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    output_longform(da4, outputdir, codebook4_annotations_output)\n",
    "    pd.Series(da4_codes).to_csv(os.path.join(outputdir, codebook4_codes_output), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125",
   "metadata": {},
   "source": [
    "## B. 1-gram frequency dataframes\n",
    "\n",
    "REQUIRES: Section A has been run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "### 1. Construct code-outcome counts dataframe `countsda1`\n",
    "\n",
    "**Pooled `speaker`, `conversation`, `annotator`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each version of the codebook\n",
    "for k, (da, annls) in enumerate([(da1, da1_codes), (da2, da2_codes), (da3, da3_codes), (da4, da4_codes)]):\n",
    "    # build the dataframe\n",
    "    countsda1 = da[[\"annotation.code.noOutcome\", \n",
    "                    \"voted.interaction.outcome\"]].value_counts()                         # compute the frequencies\n",
    "\n",
    "    for pr in np.array(np.meshgrid(annls, [\"F\", \"S\"])).T.reshape(-1,2):                  # fill in empty rows\n",
    "        idx = tuple(pr)\n",
    "        if not idx in countsda1.index:\n",
    "            countsda1[idx] = 0\n",
    "\n",
    "    countsda1 = countsda1.sort_index().to_frame().reset_index()                          # fix the formatting\n",
    "\n",
    "    countsda1 = countsda1.rename(columns={\"annotation.code.noOutcome\" : \"code\",          # fix the naming\n",
    "                                          \"voted.interaction.outcome\" : \"outcome\", \n",
    "                                          0 : \"count\"})\n",
    "    \n",
    "    # preview for debugging\n",
    "    show(countsda1, rows=5, cols=None, width=None)\n",
    "    \n",
    "    # output it\n",
    "    if output:\n",
    "        countsda1.to_csv(os.path.join(outputdir, \"codebook{}_{}\".format(k+1, code_counts_output)), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "### 2. Construct conversation-annotator-code-speaker-outcome counts dataframe `countsda2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#        'quote.text', 'annotation.code', 'annotation.creatingUser',\n",
    "#        'annotation.creationDateTime', 'quote.startPosition',\n",
    "#        'quote.endPosition', 'quote.creatingUser', 'quote.creationDateTime',\n",
    "#        'quote.modifyingUser', 'quote.modifiedDateTime', 'document.name',\n",
    "#        'document.creatingUser', 'document.creationDateTime',\n",
    "#        'document.modifyingUser', 'document.modifiedDateTime',\n",
    "#        'document.plainTextPath', 'document.richTextPath', 'annotation.guid',\n",
    "#        'annotation.codeRef.guid', 'quote.guid', 'document.guid',\n",
    "#        'quote.paragraphStartPosition', 'quote.paragraphEndPosition',\n",
    "#        'quote.paragraphText', 'quote.speaker', 'quote.speakerIsLearner',\n",
    "#        'annotation.original_code', 'interaction.number', 'interaction.len',\n",
    "#        'interaction.requests', 'interaction.outcome', 'interaction.strict',\n",
    "#        'interaction.strict_len', 'annotation.code.noOutcome',\n",
    "#        'annotation.code.noRequestOutcome', 'voted.interaction.requests', 'voted.interaction.outcome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_conv_ann_speaker_outcome_longform_counts(k, da, annls):\n",
    "    # compute the frequencies\n",
    "    countsda2 = da[[\"document.name\", \"interaction.number\", \"annotation.creatingUser\", # group by interaction-annotator\n",
    "                    \"annotation.code.noOutcome\", \"quote.speakerIsLearner\",            # group by annotation and speaker\n",
    "                    \"voted.interaction.requests\", \"interaction.requests\",             # keep these around\n",
    "                    \"voted.interaction.outcome\", \"interaction.outcome\"]].value_counts()\n",
    "    countsda2 = countsda2.sort_index().to_frame()                                     # fix the formatting\n",
    "    countsda2 = countsda2.rename(columns={0 : \"count\"})                               # fix the naming\n",
    "\n",
    "    # debugging\n",
    "    # show(countsda2.head(2))\n",
    "\n",
    "    # pivot to fill in empty values (and compute conversation lengths)\n",
    "    countsda2 = countsda2.unstack(level=[\"annotation.code.noOutcome\", \"quote.speakerIsLearner\"], \n",
    "                                  fill_value=0).copy()\n",
    "    \n",
    "    # add missing code-speakers\n",
    "    cols_to_add = []\n",
    "    for pr in np.array(np.meshgrid(annls, [False, True])).T.reshape(-1,2):                  # fill in empty rows\n",
    "        idx = (\"count\", pr[0], pr[1] == \"True\") # sorry about this one\n",
    "        if not idx in countsda2.columns:\n",
    "            cols_to_add.append(idx)\n",
    "    #print(\"Included code-speakers:\", countsda2.shape[1])\n",
    "    #print(\"Missing code-speakers:\", len(cols_to_add))\n",
    "    countsda2 = pd.concat([countsda2, \n",
    "                           pd.DataFrame(0, index=countsda2.index, columns=cols_to_add)], \n",
    "                          axis = 1) #countsda2[cols_to_add] = 0\n",
    "    \n",
    "    countsda2.columns = countsda2.columns.set_names([\"\", \"annotation.code.noOutcome\", \"quote.speakerIsLearner\"])\n",
    "    \n",
    "    # debugging\n",
    "    # show(countsda2, cols=None)\n",
    "    # print(countsda2.columns.names)\n",
    "    #break\n",
    "\n",
    "    # compute the conversation lengths according to each annotator (for codebook 1 this should\n",
    "    # agree with the version in the dataframe)\n",
    "    tmp = countsda2[\"count\"].sum(axis=1) #.astype(np.int64)\n",
    "    assert(tmp.min() >= 2)\n",
    "\n",
    "    # we have to make a lot of copies of this column because it doesn't broadcast automatically when we restack\n",
    "    for col in countsda2.columns:\n",
    "        countsda2[(\"interaction.length\", col[1], False)] = tmp\n",
    "        countsda2[(\"interaction.length\", col[1], True)] = tmp\n",
    "\n",
    "    # make the whole thing vertical again (apparently this fills in more empty values)\n",
    "    countsda2 = countsda2.stack(level=[\"annotation.code.noOutcome\", \"quote.speakerIsLearner\"], \n",
    "                                dropna=False)\n",
    "    countsda2 = countsda2.fillna(0).astype(np.int64)\n",
    "\n",
    "    # debugging\n",
    "    #show(countsda2, cols=None)\n",
    "\n",
    "    # clean up some formatting things\n",
    "    countsda2 = countsda2.reset_index() # level=\"interaction.outcome\"\n",
    "\n",
    "    countsda2 = countsda2.rename(columns={\"document.name\" : \"document\",  \n",
    "                                          \"interaction.number\" : \"conversation_number\",\n",
    "                                          \"annotation.creatingUser\" : \"annotator\", \n",
    "                                          \"voted.interaction.requests\" : \"request\", \n",
    "                                          \"voted.interaction.outcome\" : \"outcome\", \n",
    "                                          \"annotation.code.noOutcome\" : \"code\", \n",
    "                                          \"quote.speakerIsLearner\" : \"speakerIsLearner\", \n",
    "                                          \"interaction.requests\" : \"nominal_request\", \n",
    "                                          \"interaction.outcome\" : \"nominal_outcome\", \n",
    "                                          \"annotation.code.noRequestOutcome\" : \"code_noRequest\", \n",
    "                                          \"interaction.length\" : \"conversation_length\"})\n",
    "    # debugging\n",
    "    #print(countsda2.shape)\n",
    "    #show(countsda2.iloc[0:5])\n",
    "    #show(countsda2.iloc[94:100])\n",
    "\n",
    "    # derived columns\n",
    "    assert(len(countsda2[countsda2[\"conversation_length\"] <= 1]) == 0)               # data validity check\n",
    "    countsda2[\"ln_conversation_length\"] = np.log(countsda2[\"conversation_length\"])   # derived column (offset)\n",
    "    assert((countsda2.isnull().sum() == 0).all())                                    # data validity check FIXME\n",
    "\n",
    "    np.power(countsda2[\"count\"], 1/2).hist(figsize=(11, 4), bins=40)                 # visualize the output\n",
    "    plt.title(\"Distribution of conversation-annotator-code-speaker frequencies\")\n",
    "    plt.xlabel(\"Square root count\")\n",
    "    plt.ylabel(\"Number of conv-ann-code-speakers\")\n",
    "    plt.show()\n",
    "\n",
    "    countsda2[\"conversation_sharedID\"] = list(zip(countsda2[\"document\"],             # derived column (grouping variable)\n",
    "                                                  countsda2[\"conversation_number\"]))\n",
    "    countsda2[\"conversation_uniqueID\"] = list(zip(countsda2[\"document\"],             # derived column (grouping variable)\n",
    "                                                  countsda2[\"annotator\"], \n",
    "                                                  countsda2[\"conversation_number\"]))\n",
    "    # debugging\n",
    "    show(countsda2, rows=4, cols=None)\n",
    "\n",
    "    # output\n",
    "    if output:\n",
    "        countsda2.to_csv(os.path.join(outputdir, \n",
    "                                      \"codebook{}_{}\".format(k+1, conversation_1gram_counts_output)), \n",
    "                         index=False, \n",
    "                         compression=\"gzip\")\n",
    "    \n",
    "    # need this for the next thing\n",
    "    return countsda2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each version of the codebook\n",
    "countsda2ls = []\n",
    "for k, (da, annls) in enumerate([(da1, da1_codes), (da2, da2_codes), (da3, da3_codes), (da4, da4_codes)]): \n",
    "    # preprocessing: annls includes outcomes so let's fix that\n",
    "    annls = annls.copy()\n",
    "    annls.remove(\"Big picture of an interaction > resolveRequest > failure\") \n",
    "    annls.remove(\"Big picture of an interaction > resolveRequest > success\")\n",
    "    annls.append(\"Big picture of an interaction > resolveRequest\")\n",
    "    \n",
    "    # now do the thing\n",
    "    countsda2 = construct_conv_ann_speaker_outcome_longform_counts(k, da, annls)\n",
    "    countsda2ls.append(countsda2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132",
   "metadata": {},
   "source": [
    "### 3. Construct conversation-annotator x code-speaker counts matrix `countsmtx1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, countsda2 in enumerate(countsda2ls):\n",
    "    # make it fat\n",
    "    countsmtx1 = countsda2.pivot(index=[\"document\", \"conversation_number\", \n",
    "                                        \"annotator\", \n",
    "                                        \"request\", \"outcome\", \n",
    "                                        \"nominal_request\", \"nominal_outcome\", \n",
    "                                        \"conversation_length\"], \n",
    "                                 columns=[\"code\", \"speakerIsLearner\"], values=\"count\")\n",
    "    # debugging\n",
    "    #show(countsmtx1.head(4))\n",
    "\n",
    "    # column name formatting (booleans to strings)\n",
    "    countsmtx1.columns = pd.MultiIndex.from_product(\n",
    "        iterables = [countsmtx1.columns.levels[0], \n",
    "                     pd.Index([\"Helper\", \"Learner\"], dtype=\"object\", name=\"speaker\")])\n",
    "    # debugging\n",
    "    #show(countsmtx1.head(4))\n",
    "\n",
    "    # column name formatting (MultiIndex to tuples)\n",
    "    countsmtx1.columns = countsmtx1.columns.to_flat_index()\n",
    "    # debugging\n",
    "    show(countsmtx1.head(4))\n",
    "\n",
    "    # row name formatting (MultiIndex to columns)\n",
    "    countsmtx1 = countsmtx1.reset_index()\n",
    "\n",
    "    # output\n",
    "    if output:\n",
    "        countsmtx1.to_csv(os.path.join(outputdir, \"codebook{}_{}\".format(k+1, countsmtx_output)), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134",
   "metadata": {},
   "source": [
    "## C. 2-gram frequency dataframes\n",
    "\n",
    "REQUIRES: Section A has been run\n",
    "\n",
    "NOTE: this isn't updated for new codebooks yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135",
   "metadata": {},
   "source": [
    "### 1. Construct conversation-annotator-2gram-speakers-outcome counts dataframe `countsda3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT\n",
    "# da        : a long-form dataframe, for a single conversation-annotator, where each item is an annotation, in sorted order\n",
    "# codecol   : specify which column to read codes from \n",
    "#             (annotation.code, annotation.code.noOutcome, or annotation.code.noOutcomeRequest)\n",
    "# annls     : alphabetical list of all codes (for indexing)\n",
    "# speakerls : [True, False] = [\"learner\", \"helper\"]\n",
    "#\n",
    "# OUTPUT\n",
    "# counts    : a counts dataframe indexed by (code 1, speaker 1, code 2, speaker 2)\n",
    "def count2grams(da, codecol, annls, speakerls=[True, False]):\n",
    "    # First, initialize a counts matrix of all zeros\n",
    "    idx = pd.MultiIndex.from_product(iterables=[annls, speakerls, annls, speakerls], \n",
    "                                     names=[\"code1\", \"speakerIsLearner1\", \"code2\", \"speakerIsLearner2\"])\n",
    "    counts = pd.DataFrame(data=0, index=idx, columns=[\"count\"], dtype=np.int64)\n",
    "    \n",
    "    # Second, iterate through the conversation, adding to the counts dataframe\n",
    "    i1, j1 = 0, 0 # start and stop indices of all colocated annotations to act as code 1\n",
    "    \n",
    "    # Find the first code 1 location range in the conversation\n",
    "    while j1 < len(da) and da.iloc[j1][\"quote.startPosition\"] == da.iloc[i1][\"quote.startPosition\"]:\n",
    "        j1 += 1\n",
    "    \n",
    "    i2, j2 = j1+1, j1+1 # start and stop indices of all colocated annotations to act as code 2\n",
    "    \n",
    "    while j1 < len(da): # for each biclique\n",
    "        # iterate over the code 2 location range\n",
    "        while j2 < len(da) and da.iloc[j2][\"quote.startPosition\"] == da.iloc[i2][\"quote.startPosition\"]:\n",
    "            # write this biclique into the counts matrix\n",
    "            for k1 in range(i1, j1):\n",
    "                counts.loc[(da.iloc[k1][codecol], da.iloc[k1][\"quote.speakerIsLearner\"], \n",
    "                           da.iloc[j2][codecol], da.iloc[j2][\"quote.speakerIsLearner\"]), \n",
    "                           \"count\"] += 1\n",
    "            j2 += 1\n",
    "        \n",
    "        # move to the next code 1 location range\n",
    "        i1, j1 = i2, j2\n",
    "        i2, j2 = j1+1, j1+1\n",
    "    \n",
    "    # store the conversation length\n",
    "    counts[\"conversation_length\"] = len(da)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count up the 2-grams\n",
    "countsda3 = da1.groupby(by=[\"document.name\", \"annotation.creatingUser\", \"interaction.number\", # group by conversation\n",
    "                            \"interaction.outcome\"])                                           # keep the outcome around\n",
    "\n",
    "countsda3 = countsda3.apply(count2grams,                                         # the function applied to each group\n",
    "                            \"annotation.code.noOutcome\",                         # second argument `codecol`\n",
    "                            np.sort(da1[\"annotation.code.noOutcome\"].unique()))  # third argument `annls`\n",
    "\n",
    "countsda3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix up the formatting\n",
    "countsda3 = countsda3.reset_index()\n",
    "\n",
    "countsda3 = countsda3.rename(columns={\"document.name\" : \"document\", \n",
    "                                      \"annotation.creatingUser\" : \"annotator\", \n",
    "                                      \"interaction.number\" : \"conversation_number\", \n",
    "                                      \"interaction.outcome\" : \"outcome\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful extras\n",
    "countsda3[\"ln_conversation_length\"] = np.log(countsda3[\"conversation_length\"])\n",
    "\n",
    "countsda3[\"conversation_sharedID\"] = list(zip(countsda3[\"document\"], \n",
    "                                              countsda3[\"conversation_number\"]))\n",
    "countsda3[\"conversation_uniqueID\"] = list(zip(countsda3[\"document\"], \n",
    "                                              countsda3[\"annotator\"], \n",
    "                                              countsda3[\"conversation_number\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "display(countsda3)\n",
    "pd.reset_option(\"display.max_colwidth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check the length of the dataframe (it's not perfect because some \n",
    "# annotators skipped some documents, but it's believable)\n",
    "print(countsda3.shape)\n",
    "print(\"\", 133*3*(46*2)**2) # num convos * num annotators * (num codes * num speakers)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    countsda3.head(20).to_csv(os.path.join(outputdir, small_conversation_2gram_counts_output), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    countsda3.to_csv(os.path.join(outputdir, conversation_2gram_counts_output), index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 3.33M rows, of which 3.30M are zeros\n",
    "countsda3[\"count\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
