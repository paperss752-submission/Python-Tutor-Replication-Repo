{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data management (individual QDPX project $\\to$ CSV files)\n",
    "\n",
    "STAGE 1 OF THE DATA PIPELINE\n",
    "\n",
    "Take an Atlas.ti project and extract the annotations into a longform CSV file (plus auxiliary info in other CSV files).\n",
    "\n",
    "Things that happen in this script:\n",
    "1. Walk XML trees in the QDPX project and generate corresponding rectangular dataframes\n",
    "2. Combine `Codebook` (code info) and `Sources` (document + annotation info) into a single dataframe\n",
    "3. Translate each \"guid\" into the human-readable interpretation (e.g., code or document name)\n",
    "4. Filter out (document, annotator) pairs not listed as \"completed\" in the Google spreadsheet\n",
    "5. Extract full quote text from chat transcripts (those stored in the XML file are truncated to a certain number of characters)\n",
    "6. In cases where the annotator failed to highlight full lines of text, fill out quotes using the chat transcript\n",
    "7. Extract the speaker identity from the quote text (as a nonnegative integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = False\n",
    "\n",
    "input_version = 2   # 2, 3, or 4 (different versions have different documents)\n",
    "input_release = 2   # this increments with updates to the data\n",
    "output_version = 17\n",
    "\n",
    "descriptions = (input_version == 2) # True for v2, False for v3 and v4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Baseline setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ET.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data\"\n",
    "qdpxdir = \"full-project-data-{}.{}\".format(input_version, input_release)\n",
    "inputdocsdir = \"sources\"\n",
    "qdefile = \"project.qde\"\n",
    "\n",
    "document_metadata_file = os.path.join(datadir, \"annotation-timeline.csv\")\n",
    "\n",
    "outputparentdir = \"../output\"\n",
    "outputchilddir = \"v{}\".format(output_version)\n",
    "outputdir = os.path.join(outputparentdir, outputchilddir)\n",
    "\n",
    "# stage 1\n",
    "usersfile = \"users.csv\"\n",
    "codesfile = \"codes.csv\"\n",
    "sourcesfile = \"raw-masked-annotations.csv\"\n",
    "samplesourcesfile = \"small-\" + sourcesfile\n",
    "notesfile = \"notes.csv\"\n",
    "linksfile = \"links.csv\"\n",
    "setsfile = \"sets.csv\"\n",
    "\n",
    "# stage 2\n",
    "speakererrorsfile = \"ambiguous-speaker-quotations.txt\"\n",
    "annotationsfile = \"human-readable-annotations.csv\"\n",
    "sampleannotationsfile = \"small-\" + annotationsfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    try:\n",
    "        os.mkdir(outputparentdir)\n",
    "    except FileExistsError:\n",
    "        print(\"High-level output directory already exists; no action taken.\")\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(outputdir)\n",
    "    except FileExistsError:\n",
    "        print(\"WARNING: low-level output directory already exists. You might want to increment your version number.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Read in the raw data\n",
    "We'll read the whole file into a big tree structure, then take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = os.path.join(datadir, qdpxdir, qdefile)\n",
    "tree = ET.parse(fin)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in root:\n",
    "    print(child.tag, \"\\n\\t\", child.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### 0. Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Users\n",
    "for user in root[0]: # \"User\"\n",
    "    print(\"User\", user.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### 1. Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Codebook > Codes\n",
    "# there are 70 of these - we'll only look at the first 3\n",
    "# root[1] is the CodeBook node\n",
    "# root[1][0] is its only child node - the Codes node - and its own children are Code nodes\n",
    "# root[1][0][0] is a Code node - access its name/label using `root[1][0][0].attrib[\"name\"]\n",
    "for code in root[1][0][0:3]: # \"Code\"\n",
    "    print(\"Code\", code.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in root[1][0][4]: # \"Code\"\n",
    "    print(\"Sub-Code\", code.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in root[1][0][4][0]: # \"Code\"\n",
    "    print(\"Sub-Sub-Code\", code.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 2. Sources (annotated documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing \"only the Sources (annotated documents)\" would give a lot of\n",
    "# output, so instead I'm only doing the first 3 quotes of the first\n",
    "# document\n",
    "\n",
    "print(\"NOTE: These aren't the real XML tags! They were too long.\\n\")\n",
    "\n",
    "doc = root[2][0] # \"TextSource\"\n",
    "print(\"Doc\", doc.attrib, \"\\n\")\n",
    "for quote in doc[0:3]: # \"PlaintextSelection\"\n",
    "    print(\"\\tQuote\", quote.attrib)\n",
    "    for code in quote: # \"Coding\"\n",
    "        print(\"\\t\\tCode\", code.attrib)\n",
    "        for ref in code: # \"CodeRef\"\n",
    "            print(\"\\t\\t\\tCodeRef\", ref.attrib)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### 3. Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Notes (the first 3)\n",
    "for note in root[3][0:3]: # \"Notes\"\n",
    "    print(\"Note\", note.attrib, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### 4. Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Links\n",
    "if not input_version in {4}:\n",
    "    for link in root[4]: # \"Link\"\n",
    "        print(\"Link\", link.attrib, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### 5. Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Sets\n",
    "if not input_version in {4}:\n",
    "    for codeSet in root[5]: # \"Set\"\n",
    "        print(\"Set\", codeSet.attrib)\n",
    "        for code in codeSet[0:min(len(codeSet), 3)]: # \"MemberCode\"\n",
    "            print(\"\\tMemberCode\", code.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Create raw dataframes (sometimes within directories)\n",
    "Here, we must split the big XML file into subtrees before reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### 0. Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols: guid, name\n",
    "usersStr = ET.tostring(root[0], encoding='utf8', method='xml')\n",
    "\n",
    "usersDa = pd.read_xml(usersStr)\n",
    "\n",
    "usersDa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### 1. Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "root[1][0][3][0].attrib # FIXME forgot that the codebook is nested now FML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_description(node):\n",
    "    if node.tag == \"{urn:QDA-XML:project:1.0}Description\":\n",
    "        assert(len(node) == 0 and len(node.attrib) == 0)\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_leaf(node):\n",
    "    if len(node) == 0:\n",
    "        return True\n",
    "    if len(node) == 1 and is_description(node[0]):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookDepth = 0\n",
    "codebookSize = 0 # only leaf nodes\n",
    "bfsq = [(root[1][0], 0)]\n",
    "curDepth = 1\n",
    "\n",
    "while len(bfsq) > 0:\n",
    "    # debugging\n",
    "    prevDepth = curDepth\n",
    "    \n",
    "    # regular stuff\n",
    "    curNode, curDepth = bfsq.pop(0)\n",
    "    \n",
    "    # debugging\n",
    "    if prevDepth != curDepth and curDepth > 0:\n",
    "        print(\"\\n\\n{}.\".format(curDepth), end = \" \")\n",
    "    try:\n",
    "        print(curNode.attrib[\"name\"], end = \"     \")\n",
    "    except(KeyError):\n",
    "        print(\"FIXME (Node type: {}; Attributes: {})\".format(curNode.tag.split(\"}\")[1], curNode.attrib), end = \"     \")\n",
    "    \n",
    "    # remove Description nodes, as they're annoying\n",
    "    if is_description(curNode):\n",
    "        continue\n",
    "    \n",
    "    # regular stuff\n",
    "    codebookDepth = curDepth\n",
    "    if is_leaf(curNode):\n",
    "        codebookSize += 1\n",
    "    for child in curNode:\n",
    "        bfsq.append((child, curDepth+1))\n",
    "    \n",
    "    # debugging\n",
    "    #if not \"name\" in curNode.attrib.keys():\n",
    "    #    print(curNode.tag, end=\", \")\n",
    "    #    print(curNode.attrib)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Codebook depth: {}\".format(codebookDepth))\n",
    "print(\"Number of interesting leaf nodes: {}\".format(codebookSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookCols = [\"guid\", \"color\", \"isCodable\", \"name\"] + [\"lvl_{}\".format(k+1) for k in range(codebookDepth)]\n",
    "print(codebookCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookArr = [None] * codebookSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_field(node, field):\n",
    "    try:\n",
    "        return node.attrib[field]\n",
    "    except(KeyError):\n",
    "        if node.tag == \"{urn:QDA-XML:project:1.0}Codes\":\n",
    "            return \"*\"\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = []\n",
    "idx = 0\n",
    "\n",
    "# pre-order dfs\n",
    "def dfs(cur, idx):\n",
    "    if not is_description(cur):\n",
    "        # leaf node\n",
    "        if is_leaf(cur):\n",
    "            # debugging\n",
    "            #print(\"{}. \".format(idx) + \" > \".join([get_node_field(node, \"name\") for node in trace]))\n",
    "            names = [get_node_field(node, \"name\") for node in trace]\n",
    "            row = [get_node_field(cur, col) for col in codebookCols[:3]] + [\" > \".join(names)] + names\n",
    "            codebookArr[idx] = row\n",
    "            idx += 1\n",
    "        # internal node\n",
    "        else:\n",
    "            for child in cur:\n",
    "                trace.append(child)\n",
    "                idx = dfs(child, idx)\n",
    "    trace.pop(len(trace) - 1)\n",
    "    return idx\n",
    "\n",
    "for node in root[1][0]:\n",
    "    trace.append(node)\n",
    "    idx = dfs(node, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookArr[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookDa = pd.DataFrame(data = codebookArr, columns = codebookCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookDa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### 2. Sources (annotated documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols: guid, name, creatingUser, creationDateTime, plainTextPath, richTextPath\n",
    "sourcesStr = ET.tostring(root[2], encoding='utf8', method='xml')\n",
    "\n",
    "sourcesDa = pd.read_xml(sourcesStr)\n",
    "\n",
    "assert(sourcesDa[\"PlainTextSelection\"].dropna().shape[0] == 0)\n",
    "sourcesDa = sourcesDa.drop(\"PlainTextSelection\", axis=1)\n",
    "\n",
    "sourcesDa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sourcesDa[\"Description\"].value_counts() # just checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources are deeply nested compared to the other stuff. This directory will look like:\n",
    "# sourcesDir = {Doc guid > (quotesDa, quotesDir)} where for each Doc,\n",
    "# quotesDir = {Quote guid > codesDa} where for each Quote, codeRefs have been pivoted\n",
    "#                                    into codesDa (I think there's only one per code)\n",
    "sourcesDir = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(5):\n",
    "    print(root[2][0][k].attrib[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quote\n",
    "quote = root[2][0][0]\n",
    "print(quote.tag)\n",
    "quote.attrib # Atlas didn't wanna store the text I guess UPDATE - Atlas has changed its mind, see cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, ann in enumerate(quote):\n",
    "    print(idx, \":\", ann)\n",
    "    print(ann.attrib)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an annotation (coding)\n",
    "ann = quote[0]\n",
    "print(ann.tag)\n",
    "ann.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a code reference\n",
    "ref = ann[0]\n",
    "print(ref.tag)\n",
    "ref.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "idx : index of the document (order of upload to Atlas)\n",
    "\"\"\"\n",
    "def get_doc_text(idx):\n",
    "    fin = sourcesDa.at[idx, \"plainTextPath\"].split(\"//\")[1]\n",
    "    #print(fin)\n",
    "    fin = os.path.join(datadir, qdpxdir, inputdocsdir, fin)\n",
    "    #print(fin)\n",
    "\n",
    "    f = open(fin)\n",
    "\n",
    "    # source document as a string\n",
    "    docstr = f.read()\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    return docstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quote.attrib\n",
    "\"targetGUID\" in code.attrib.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebookDa[codebookDa[\"lvl_2\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols of these: guid, name, creatingUser, creationDateTime, startPosition, endPosition\n",
    "c = 0\n",
    "for doc_idx, doc in enumerate(root[2]):\n",
    "    # print(doc.attrib[\"name\"])\n",
    "    quotesStr = ET.tostring(doc, encoding='utf8', method='xml')\n",
    "    \n",
    "    try:\n",
    "        quotesDa = pd.read_xml(quotesStr)\n",
    "        try:\n",
    "            assert(quotesDa[\"Coding\"].dropna().shape[0] == 0) # should be able to do this with len() instead\n",
    "            quotesDa = quotesDa.drop(\"Coding\", axis=1)\n",
    "        except(KeyError):\n",
    "            print(\"WARNING: Document {} has no Coding's.\\n\".format(doc.attrib[\"name\"]))\n",
    "    \n",
    "    except(ValueError):\n",
    "        # document hasn't been annotated\n",
    "        sourcesDa.drop(sourcesDa.index[sourcesDa[\"guid\"] == doc.attrib[\"guid\"]], inplace=True)\n",
    "        continue\n",
    "    \n",
    "    # remove rows that are just Descriptions\n",
    "    if \"Description\" in quotesDa.columns:\n",
    "        print(\"Description found -- File: {}, GUID: {}\".format(doc.attrib[\"name\"], doc.attrib[\"name\"]))\n",
    "        assert(doc.attrib[\"guid\"] == \"B889885D-0073-4C1F-B748-106B7C01FD10\") # THIS MAY CHANGE\n",
    "        quotesDa = quotesDa[quotesDa[\"Description\"].isna()].drop(columns=[\"Description\"])\n",
    "        #display(quotesDa)\n",
    "    \n",
    "    quotesDir = {}\n",
    "    \n",
    "    for quote in doc:\n",
    "        if c < 3:\n",
    "            print(\"quote: {}\".format(quote.attrib[\"guid\"]))\n",
    "            c += 1\n",
    "        codesStr = ET.tostring(quote, encoding='utf8', method='xml')\n",
    "        try:\n",
    "            codesDa = pd.read_xml(codesStr)\n",
    "        except(ValueError):\n",
    "            # Sometimes we delete a coding but the orphaned quotation\n",
    "            # stays in the file. This is uninteresting so we skip it.\n",
    "            if \"guid\" in quote.attrib.keys():\n",
    "                quotesDa = quotesDa.loc[quotesDa[\"guid\"] != quote.attrib[\"guid\"]].reset_index(drop=True)\n",
    "            continue\n",
    "        \n",
    "        # initialize derived columns to store information in XML child nodes\n",
    "        codesDa[\"isCode\"] = False\n",
    "        codesDa[\"isNote\"] = False\n",
    "        codesDa[\"CodeRef.targetGUID\"] = np.nan\n",
    "        codesDa[\"NoteRef.targetGUID\"] = np.nan\n",
    "        \n",
    "        # upward reference to the quote that all these codes were assigned to\n",
    "        codesDa[\"quoteGUID\"] = quote.attrib[\"guid\"]\n",
    "        \n",
    "        # code- and note-specific actions\n",
    "        for idx, coding in enumerate(quote): # \"Coding\"\n",
    "            if len(coding) == 1:\n",
    "                code = coding[0]\n",
    "            else:\n",
    "                print(\"WARNING: Coding {} has {} Refs\".format(coding.tag, len(coding)))\n",
    "                print(code.attrib)\n",
    "                1/0\n",
    "            \n",
    "            if code.tag == \"{urn:QDA-XML:project:1.0}CodeRef\":\n",
    "                codesDa.at[idx, \"isCode\"] = True\n",
    "                if \"targetGUID\" in code.attrib:\n",
    "                    codesDa.at[idx, \"CodeRef.targetGUID\"] = code.attrib[\"targetGUID\"]\n",
    "                else:\n",
    "                    # debugging\n",
    "                    warning = \"WARNING: Document {} > Quote \\\"{}\\\" > Code \\\"{}\\\" has {} references\\n\".format(\n",
    "                        doc.attrib[\"name\"], \n",
    "                        quote.attrib[\"name\"], \n",
    "                        code.attrib, \n",
    "                        len(code))\n",
    "                    print(warning)\n",
    "            elif code.tag == \"{urn:QDA-XML:project:1.0}NoteRef\":\n",
    "                codesDa.at[idx, \"isNote\"] = True\n",
    "                codesDa.at[idx, \"NoteRef.targetGUID\"] = code.attrib[\"targetGUID\"]\n",
    "            else:\n",
    "                # debugging\n",
    "                warning = \"WARNING: unrecognized XML tag in Document {} > Quote {} > {} {}\\n\".format(\n",
    "                    doc.attrib[\"name\"], \n",
    "                    quote.attrib[\"name\"], \n",
    "                    code.tag, \n",
    "                    code.attrib)\n",
    "                print(warning)\n",
    "        \n",
    "        # default-initialize any columns we need for merging later\n",
    "        tagset = {coding[0].tag for coding in quote}\n",
    "        \n",
    "        if not \"{urn:QDA-XML:project:1.0}CodeRef\" in tagset:\n",
    "            codesDa[\"guid\"] = np.nan\n",
    "            codesDa[\"creatingUser\"] = np.nan\n",
    "            codesDa[\"creationDateTime\"] = np.nan\n",
    "        if not \"{urn:QDA-XML:project:1.0}NoteRef\" in tagset:\n",
    "            codesDa[\"targetGUID\"] = np.nan\n",
    "        else:\n",
    "            print(\"Document {} > quote {} has notes\".format(doc.attrib[\"name\"], quote.attrib[\"name\"]))\n",
    "        \n",
    "        # write output\n",
    "        quotesDir[quote.attrib[\"guid\"]] = codesDa\n",
    "\n",
    "    # write more output\n",
    "    sourcesDir[doc.attrib[\"guid\"]] = (quotesDa, quotesDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell only runs correctly for Project Version 3 (I hardcoded the index for testing)\n",
    "if input_version in {3}:\n",
    "    quotesDa = sourcesDir[\"E266595E-8846-4BB3-904F-A818FDD5DC0B\"][0]\n",
    "    display(quotesDa[quotesDa[\"guid\"] == \"D087E98C-3500-429E-A6A0-43EB9388E7B1\"])\n",
    "    display(quotesDa[quotesDa[\"guid\"] == \"B4E46844-CBFA-431C-BCFD-3EB82155E6CA\"])\n",
    "    display(quotesDa[quotesDa[\"guid\"] == \"799E4C5D-76F8-4CFA-A438-BE8A1B92157B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotesDa.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "codesDa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "code.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0\n",
    "q = 1\n",
    "(sourcesDir[list(sourcesDir.keys())[d]][q])[list(sourcesDir[list(sourcesDir.keys())[d]][q].keys())[2]]\n",
    "#len(sourcesDir[list(sourcesDir.keys())[d]][q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcesDa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "See the first dataframe below for a \"standard\" `quotesDa` (all elements are either `Coding`s or `NoteRef`s).\n",
    "\n",
    "See the second dataframe below for a \"standard\" `codesDa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check I did it right\n",
    "#display(sourcesDir[\"378A15D0-C2D3-4E73-AC3E-DC9B260BD9D4\"][0].head(3)) # quotesDa\n",
    "#display(sourcesDir[\"378A15D0-C2D3-4E73-AC3E-DC9B260BD9D4\"][1][\"49EB5814-CAAE-43DD-B03D-E77B98C7753C\"]) # codesDa\n",
    "src = list(sourcesDir.keys())[0]\n",
    "display(sourcesDir[src][0].head(3))\n",
    "display(sourcesDir[src][1][list(sourcesDir[src][1].keys())[0]]) # codesDa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "### 3. Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols: guid, name, creatingUser, creationDateTime, modifyingUser, modifiedDateTime, plainTextPath, richTextPath\n",
    "notesStr = ET.tostring(root[3], encoding='utf8', method='xml')\n",
    "\n",
    "notesDa = pd.read_xml(notesStr)\n",
    "\n",
    "notesDa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### 4. Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols: guid, name, color, direction, originGUID, targetGUID\n",
    "if not input_version in {4}:\n",
    "    linksStr = ET.tostring(root[4], encoding='utf8', method='xml')\n",
    "\n",
    "    linksDa = pd.read_xml(linksStr)\n",
    "\n",
    "    display(linksDa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "### 5. Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols: name, guid\n",
    "if not input_version in {4}:\n",
    "    setsStr = ET.tostring(root[5], encoding='utf8', method='xml')\n",
    "\n",
    "    setsDa = pd.read_xml(setsStr)\n",
    "\n",
    "    memberTypes = list(setsDa.columns)[2:]\n",
    "\n",
    "    for memberType in memberTypes:\n",
    "        newColName = memberType + \".targetGUIDs\"\n",
    "        setsDa.rename(columns={memberType : newColName}, inplace=True)\n",
    "        setsDa[newColName] = \"N/A\"\n",
    "\n",
    "    display(setsDa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not input_version in {4}:\n",
    "    for idx, codeSet in enumerate(root[5]):\n",
    "        members = {member.tag : [] for member in codeSet}\n",
    "        for member in codeSet:\n",
    "            members[member.tag].append(member.attrib[\"targetGUID\"])\n",
    "        #print(members, \"\\n\")\n",
    "        for tag, targetGUIDs in members.items():\n",
    "            col = tag.split('}')[1] + \".targetGUIDs\"\n",
    "            setsDa.at[idx, col] = targetGUIDs\n",
    "\n",
    "    display(setsDa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "## Now that we have all the data out of XML, we need to consolidate it\n",
    "Specifically, No. 2: Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "### 2. Sources\n",
    "We want to merge all the different dictionaries and dataframes into a single dataframe of annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the relevant data structures (for now) are sourcesDa and sourcesDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sourcesDir = doc guid -> (quotesDa, quotesDir)\n",
    "# quotesDa = quote guid x [text, start, end, time, doc, etc.]\n",
    "# quotesDir = quote guid -> codesDa\n",
    "# codesDa = code/noteref x [code vs note flag, note target guid, quote guid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminding myself what they look like...\n",
    "src_guid_ex = sourcesDa[\"guid\"][0]\n",
    "quotesDa_ex = sourcesDir[src_guid_ex][0]\n",
    "quotesDir_ex = sourcesDir[src_guid_ex][1]\n",
    "quote_guid_ex = list(quotesDir_ex.keys())[0]\n",
    "codesDa_ex = quotesDir_ex[quote_guid_ex]\n",
    "\n",
    "display(\"sources\", sourcesDa.head(3)) # documentsDa\n",
    "display(\"quotes\", quotesDa_ex.head(3)) # quotesDa\n",
    "display(\"annotations\", codesDa_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"22BDC312-CA2D-47C3-ABF8-453195276C54\" in sourcesDa[\"guid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"22BDC312-CA2D-47C3-ABF8-453195276C54\" in quotesDa_ex[\"guid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"22BDC312-CA2D-47C3-ABF8-453195276C54\" in codesDa_ex[\"targetGUID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotesDa_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(quotesDir_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: why do I have a CodeRef column and both {}.targetGUID columns, but\n",
    "# no NoteRef column? Need to check whether Notes were taken at all\n",
    "for key, val in quotesDir_ex.items():\n",
    "    display(val)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for doc, (quotesDa, quotesDir) in sourcesDir.items():\n",
    "    #display(quotesDa)\n",
    "    for quote, codesDa in quotesDir.items():\n",
    "        count += 1\n",
    "        #print(quote)\n",
    "        #display(codesDa)\n",
    "    print(\"Finished document {} (total {} quotes)\".format(doc, count))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"B889885D-0073-4C1F-B748-106B7C01FD10\" in sourcesDir.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "docDir = {}\n",
    "\n",
    "for doc, (quotesDa, quotesDir) in sourcesDir.items():\n",
    "    #da = None\n",
    "    #for quote, codesDa in quotesDir.items():\n",
    "    #    tmpDa = codesDa.set_index(\"guid\")\n",
    "    #    if da is None:\n",
    "    #        da = tmpDa\n",
    "    #    else:\n",
    "    #        da = da.append(tmpDa)\n",
    "    #print(doc)\n",
    "    codesDa = pd.concat(quotesDir.values(), ignore_index=True)\n",
    "    docDir[doc] = codesDa.add_prefix(\"annotation.\").merge(quotesDa.add_prefix(\"quote.\"), \n",
    "                                left_on=\"annotation.quoteGUID\", \n",
    "                                right_on=\"quote.guid\", \n",
    "                                suffixes=(\"__ERROR-left\", \"__ERROR-right\"), \n",
    "                                how=\"outer\")\n",
    "    docDir[doc][\"quote.documentGUID\"] = doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(docDir[src_guid_ex].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.concat(docDir.values(), ignore_index=True).astype({\"quote.startPosition\": \"int64\", \n",
    "                                                           \"quote.endPosition\": \"int64\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if descriptions:\n",
    "    display(sourcesDa[sourcesDa[\"Description\"].notna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if descriptions:\n",
    "    display(sourcesDa[\"Description\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.merge(sourcesDa.add_prefix(\"document.\"), \n",
    "              left_on=\"quote.documentGUID\", \n",
    "              right_on=\"document.guid\", \n",
    "              suffixes=(\"__ERROR-left\", \"__ERROR-right\"), \n",
    "              how=\"outer\")\n",
    "da.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"annotation.isCode\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"annotation.isNote\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(da.head(5))\n",
    "pd.reset_option(\"max_columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(da[\"annotation.CodeRef\"].value_counts()) == 0) # remove this in the next cell\n",
    "display(da[\"annotation.isCode\"].value_counts()) # FIXME check that the mechanism I'm using to decide this is still valid\n",
    "assert(len(da[\"annotation.targetGUID\"].value_counts()) == 0) # remove this in the next cell\n",
    "\n",
    "# these are fine, just rare\n",
    "if descriptions:\n",
    "    #display(da[\"quote.Description\"].value_counts()) # FIXME this makes input version 5 break\n",
    "    display(da[\"document.Description\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.drop(columns=[\"annotation.CodeRef\", \"annotation.targetGUID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from annotation.CodeRef.guid\n",
    "codebookDa[codebookDa[\"guid\"] == \"AE184BD2-6DF4-492B-B4FE-F7D446C30B51\"] # yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "### Output sources and all the other data as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    usersDa.to_csv(os.path.join(outputdir, usersfile))\n",
    "    codebookDa.to_csv(os.path.join(outputdir, codesfile))\n",
    "    da.to_csv(os.path.join(outputdir, sourcesfile))\n",
    "    da.head(20).to_csv(os.path.join(outputdir, samplesourcesfile)) # for easy visualization on GitHub\n",
    "    notesDa.to_csv(os.path.join(outputdir, notesfile))\n",
    "    if not input_version in {4}:\n",
    "        linksDa.to_csv(os.path.join(outputdir, linksfile))\n",
    "        setsDa.to_csv(os.path.join(outputdir, setsfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "## Consolidate even more\n",
    "\n",
    "Instead of 5 dataframes, we want 1 (or $<$5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "### Drop value-less columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols = []\n",
    "for col in da.columns:\n",
    "    #print(col, \":\", len(da[col].unique()))\n",
    "    if len(da[col].unique()) == 1:\n",
    "        dropcols = dropcols + [col]\n",
    "print(dropcols)\n",
    "da1 = da.drop(columns=dropcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "equiv_cols = {#\"annotation.quoteGUID\" : \"quote.guid\", \n",
    "              #\"annotation.targetGUID\" : \"annotation.NoteRef.targetGUID\", \n",
    "              \"quote.documentGUID\" : \"document.guid\"}\n",
    "\n",
    "for left, right in equiv_cols.items():\n",
    "    if (da1[left].eq(da1[right]) | (da1[left].isna() & da1[right].isna())).all():\n",
    "        da1.drop(columns=left, inplace=True)\n",
    "    else:\n",
    "        print(\"oops, {} doesn't always equal {}\".format(left, right))\n",
    "        display(da1[da1[left].ne(da1[right])][left].value_counts())\n",
    "        display(da1[da1[left].ne(da1[right])][right].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {\"annotation.creatingUser\" : \"annotation.creatingUserGUID\", \n",
    "          \"quote.creatingUser\" : \"quote.creatingUserGUID\", \n",
    "          \"quote.modifyingUser\" : \"quote.modifyingUserGUID\", \n",
    "          \"document.creatingUser\" : \"document.creatingUserGUID\"}\n",
    "da1.rename(columns=rename, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(da1.head(5))\n",
    "pd.reset_option(\"max_columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "### Translate GUIDs into words, where possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_to_identifier(guid, df, guid_col, id_col, id_type):\n",
    "    rows = df[df[guid_col] == guid].reset_index()\n",
    "    if len(rows) != 1:\n",
    "        #if guid is np.nan or guid is None:\n",
    "        if pd.isnull(guid):\n",
    "            return np.nan\n",
    "        err = \"ERROR query for {} guid {} produced {} results with the following identifier(s): \\n\\t{}\".format(\n",
    "            id_type, guid, len(rows), \"\\n\\t\".join(rows[id_col]))\n",
    "        raise Exception(err)\n",
    "    return rows.at[0, id_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guid_to_identifier(\"57500D78-CB6B-4955-9A3C-4A3940F6263A\", usersDa, \"guid\", \"name\", \"user\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE this code block is *supposed* to produce an error\n",
    "try:\n",
    "    print(guid_to_identifier(\"fake-guid\", usersDa, \"guid\", \"name\", \"user\"))\n",
    "except Exception as e:\n",
    "    assert(str(e).startswith('ERROR query for user guid fake-guid produced 0 results with the following identifier(s)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_to_user(guid):\n",
    "    return guid_to_identifier(guid, usersDa, \"guid\", \"name\", \"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_to_code(guid):\n",
    "    return guid_to_identifier(guid, codebookDa, \"guid\", \"name\", \"code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_to_note(guid):\n",
    "    return guid_to_identifier(guid, notesDa, \"guid\", \"name\", \"note\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test them each once\n",
    "print(guid_to_user(\"8F219B13-6EC7-4DBD-A8B7-73F4C1A66B69\"))\n",
    "print(guid_to_code(\"AE184BD2-6DF4-492B-B4FE-F7D446C30B51\"))\n",
    "#print(guid_to_note(\"F3ACD375-0E92-4324-BE15-727C4651C1EE\")) # not using notes anymore apparently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for display purposes - to visualize the columns with GUID values\n",
    "cols = [\"annotation.creationDateTime\", \n",
    "        #\"annotation.isCode\", # got rid of these cause we only have Codes now(?)\n",
    "        #\"annotation.isNote\", \n",
    "        \"quote.name\", # not sure why this started causing errors all of a sudden\n",
    "        \"quote.creationDateTime\",\n",
    "        \"quote.startPosition\", \n",
    "        \"quote.endPosition\", \n",
    "        \"quote.modifiedDateTime\", \n",
    "        \"document.name\", \n",
    "        \"document.creationDateTime\", \n",
    "        \"document.plainTextPath\", \n",
    "        \"document.richTextPath\"]\n",
    "display(da1.drop(columns=[col for col in cols if col in da1.columns]).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(da1[\"annotation.NoteRef.targetGUID\"].value_counts(), \"\\n\")\n",
    "print(da1[\"quote.modifyingUserGUID\"].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "#### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what's going on\n",
    "#da1[da1[\"annotation.creatingUserGUID\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the user-based ones\n",
    "da1[\"annotation.creatingUser\"] = da1[[\"annotation.creatingUserGUID\"]].applymap(guid_to_user)[\"annotation.creatingUserGUID\"]\n",
    "da1[\"quote.creatingUser\"] = da1[[\"quote.creatingUserGUID\"]].applymap(guid_to_user)[\"quote.creatingUserGUID\"]\n",
    "da1[\"quote.modifyingUser\"] = da1[[\"quote.modifyingUserGUID\"]].applymap(guid_to_user)[\"quote.modifyingUserGUID\"]\n",
    "if not input_version in {2, 4}:\n",
    "    da1[\"document.creatingUser\"] = da1[[\"document.creatingUserGUID\"]].applymap(guid_to_user)[\"document.creatingUserGUID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(da1.head(3))\n",
    "pd.reset_option(\"max_columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(da1[\"annotation.creatingUser\"].value_counts(), \"\\n\") # cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "#### Annotations (Codes and Notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1[da1[\"annotation.CodeRef.targetGUID\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the code-based ones\n",
    "da1[\"annotation.CodeRef.target\"] = da1[[\"annotation.CodeRef.targetGUID\"]].applymap(guid_to_code)[\"annotation.CodeRef.targetGUID\"]\n",
    "da1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the note-based ones (there's only one)\n",
    "#da1[\"annotation.NoteRef.target\"] = da1[[\"annotation.NoteRef.targetGUID\"]].applymap(guid_to_note)[\"annotation.NoteRef.targetGUID\"]\n",
    "#da1.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "da1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"quote.name\", \n",
    "        \"annotation.isCode\", \n",
    "        \"annotation.isNote\", \n",
    "        \"annotation.CodeRef.target\", \n",
    "        \"annotation.NoteRef.target\", \n",
    "        \"annotation.creatingUser\", \n",
    "        \"annotation.creationDateTime\", \n",
    "        \"quote.startPosition\", \n",
    "        \"quote.endPosition\", \n",
    "        \"quote.creatingUser\", \n",
    "        \"quote.creationDateTime\", \n",
    "        \"quote.modifyingUser\", \n",
    "        \"quote.modifiedDateTime\", \n",
    "        \"document.name\", \n",
    "        \"document.creatingUser\", \n",
    "        \"document.creationDateTime\", \n",
    "        \"document.modifyingUser\",\n",
    "        \"document.modifiedDateTime\", \n",
    "        \"document.plainTextPath\", \n",
    "        \"document.richTextPath\", \n",
    "        \"annotation.guid\", \n",
    "        \"annotation.CodeRef.targetGUID\", \n",
    "        \"quote.guid\", \n",
    "        \"document.guid\"]\n",
    "\n",
    "da2 = da1.copy()\n",
    "da2 = da2[[col for col in cols if col in da2.columns]]\n",
    "\n",
    "rename = {\"quote.name\" : \"quote.text\",\n",
    "          \"annotation.CodeRef.target\" : \"annotation.code\", \n",
    "          #\"annotation.NoteRef.target\" : \"annotation.note\", \n",
    "          \"annotation.CodeRef.targetGUID\" : \"annotation.codeRef.guid\"}\n",
    "\n",
    "da2.rename(columns=rename, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(da2.head(3))\n",
    "pd.reset_option(\"max_columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129",
   "metadata": {},
   "source": [
    "### Throw out document-annotator pairs not marked as part of the intentional dataset\n",
    "This removes documents that are incomplete, annotated under different schemes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130",
   "metadata": {},
   "source": [
    "From now on, we only work with data from documents whose annotations are complete according to the spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(da2[da2[\"document.name\"].str.endswith(\".txt\")].shape)\n",
    "# print(da2[~da2[\"document.name\"].str.endswith(\".txt\")].shape)\n",
    "# da3 = da2[da2[\"document.name\"].str.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotators = [\"Annotator_0\", \"Annotator_1\", \"Annotator_2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133",
   "metadata": {},
   "source": [
    "Read in the metadata file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_metadata = pd.read_csv(document_metadata_file)\n",
    "document_metadata = document_metadata.set_index(\"Document Name\")\n",
    "document_metadata = document_metadata.drop(index=\"103\", columns=[\"Unnamed: 10\", \"Unnamed: 11\"])\n",
    "document_metadata = document_metadata.fillna({\"Notes\" : \"\"})\n",
    "document_metadata = document_metadata.fillna({annotator : False for annotator in annotators})\n",
    "\n",
    "display(document_metadata.head(3))\n",
    "# display(document_metadata.tail(8)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_metadata[\"Annotator_2\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136",
   "metadata": {},
   "source": [
    "From now on, we only work with data from documents whose annotations are complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound but incomplete filtering\n",
    "da3 = da2[da2[\"document.name\"].isin(document_metadata.index.unique())]\n",
    "da3 = da3.reset_index(drop=True)\n",
    "print(\"{} to {}\".format(da2.shape, da3.shape))\n",
    "da3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from the dataframe\n",
    "du = pd.Series(list(zip(da3[\"document.name\"], \n",
    "                        da3[\"annotation.creatingUser\"].str.split(\" \").str[0])), # first names only\n",
    "               index = da3.index)\n",
    "\n",
    "# read from the metadata\n",
    "completed = np.concatenate([list(zip(document_metadata.index[document_metadata[annotator]], \n",
    "                                    itertools.repeat(annotator))) \n",
    "                           for annotator in annotators], axis=0)\n",
    "\n",
    "# stupid numpy autoconvert thing\n",
    "completed = completed.T\n",
    "completed = list(zip(completed[0], completed[1]))\n",
    "#print(len(completed))\n",
    "\n",
    "fil = du.isin(completed)\n",
    "#print(fil.value_counts())\n",
    "\n",
    "print(da3.shape)\n",
    "da3 = da3[fil]\n",
    "print(da3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139",
   "metadata": {},
   "source": [
    "### Get more text from the original documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140",
   "metadata": {},
   "source": [
    "Read in all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "doctext = {}\n",
    "docs = da3[\"document.plainTextPath\"].unique()\n",
    "docfnames = pd.Series(docs).str.split(\"//\").str[1]\n",
    "\n",
    "for i, doc in enumerate(docfnames):\n",
    "    #print(doc)\n",
    "    fin = os.path.join(datadir, qdpxdir, inputdocsdir, doc)\n",
    "    f = open(fin)\n",
    "    doctext[docs[i]] = f.read() # source document as a string\n",
    "    f.close()\n",
    "\n",
    "print(len(doctext), len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142",
   "metadata": {},
   "source": [
    "Force the `quote.text` column to contain the entire quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_info = pd.Series(zip(da3[\"document.plainTextPath\"], da3[\"quote.startPosition\"], da3[\"quote.endPosition\"]), index=da3.index)\n",
    "quote_text = quote_info.map(lambda v, doctext=doctext : doctext[v[0]][v[1]:v[2]])\n",
    "da3[\"quote.text\"] = quote_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144",
   "metadata": {},
   "source": [
    "Extract the speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parstart = quote_info.map(lambda v, doctext=doctext : doctext[v[0]].rfind(\"\\n\", 0, v[1]) + 1)\n",
    "parstart = quote_info.map(lambda v, doctext=doctext : doctext[v[0]].rfind(\"\\n2019-\", 0, v[1]+5) + 1)\n",
    "(parstart == da3[\"quote.startPosition\"]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "parend = quote_info.map(lambda v, doctext=doctext : doctext[v[0]].find(\"\\n\", v[2]))\n",
    "(parend == da3[\"quote.endPosition\"]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_info = pd.Series(zip(da3[\"document.plainTextPath\"], parstart, parend), index=da3.index)\n",
    "par_text = par_info.map(lambda v, doctext=doctext : doctext[v[0]][v[1]:v[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148",
   "metadata": {},
   "source": [
    "Debug the speaker scraping step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for items that don't have a speaker (usually they're code)\n",
    "err = \"**** MISSING SPEAKERS ****\\n\\n\"\n",
    "fil = ~par_text.str.lower().str.contains(\" person \")\n",
    "tmp = par_text[fil]\n",
    "for i in tmp.index:\n",
    "    err += \"[{}] {}:{}, {}, {}, {}\\n\".format(i, parstart[i], parend[i], \n",
    "                                             da3.loc[i, \"document.name\"], \n",
    "                                             da3.loc[i, \"annotation.creatingUser\"], \n",
    "                                             da3.loc[i, \"annotation.code\"])\n",
    "    err += tmp[i] + \"\\n\\n\"\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for items that don't have a speaker at the right index (results from the previous check are excluded)\n",
    "# this is now redundant to the next cell\n",
    "fil = ~fil & ~(par_text.str[24:32].str.lower() == \" person \")\n",
    "fil &= ~(par_text.str[24:46].str.lower() == \" code change : person \")\n",
    "fil &= ~(par_text.str[24:48].str.lower() == \" executed code : person \")\n",
    "tmp = par_text[fil]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for items that have multiple speakers (we don't exclude the previous ones here, as there are few)\n",
    "#fil = ~fil & (par_text.str.find(\"2019-\") != par_text.str.rfind(\"2019-\"))\n",
    "fil = par_text.str.find(\"2019-\") != par_text.str.rfind(\"2019-\")\n",
    "tmp = par_text[fil]\n",
    "print(len(tmp), \"items checked\")\n",
    "problems = {}\n",
    "for j in tmp.index: # this could be done more concisely using re, but I don't feel like scrolling all the way up to load the package\n",
    "    s = tmp[j]\n",
    "    i = 0\n",
    "    speakers = {}\n",
    "    while i != -1:\n",
    "        k, l = None, None\n",
    "        if s[i+24 : i+32].lower() == \" person \":\n",
    "            k = i + 32\n",
    "            l = s.find(\":\", i+32)\n",
    "            line = s[l+1:s.find(\"\\n\", l+1)].strip()\n",
    "            if line == \"(hello)\" or line == \"(bye)\":\n",
    "                k, l = None, None # skip these lines\n",
    "        elif s[i+24 : i+45].lower() == \" code change : person \":\n",
    "            k = i+45\n",
    "            l = s.find(\"\\n\", i+45)\n",
    "        elif s[i+24 : i+48].lower() == \" executed code : person \":\n",
    "            k = i+47\n",
    "            l = s.find(\"#########\", i+47)\n",
    "        else:\n",
    "            #print(\"~[{}] {}:{}, {}, {}, {}\".format(j, parstart[j], parend[j], \n",
    "            #                                      da3.loc[j, \"document.name\"], \n",
    "            #                                      da3.loc[j, \"annotation.creatingUser\"], \n",
    "            #                                      da3.loc[j, \"annotation.code\"]))\n",
    "            #print(s[i:], \"\\n\")\n",
    "            problems[(da3.loc[j, \"document.name\"], da3.loc[j, \"quote.startPosition\"], \n",
    "                      da3.loc[j, \"quote.endPosition\"])] = (da3.loc[j, \"document.plainTextPath\"], \n",
    "                                                           parstart[j], parend[j], speakers.copy())\n",
    "        \n",
    "        if k is not None and l is not None and k < l < len(s) and s[k:l].strip().isdigit():\n",
    "            key = s[k:l].strip()\n",
    "            if key in speakers.keys():\n",
    "                speakers[key] += 1\n",
    "            else:\n",
    "                speakers[key] = 1 # this is where the person ID is\n",
    "        \n",
    "        i = s.find(\"2019-\", i+33)\n",
    "    if len(speakers) != 1:\n",
    "        #print(\"[{}] {}:{}, {}, {}, {}\".format(j, parstart[j], parend[j], \n",
    "        #                                      da3.loc[j, \"document.name\"], \n",
    "        #                                      da3.loc[j, \"annotation.creatingUser\"], \n",
    "        #                                      da3.loc[j, \"annotation.code\"]))\n",
    "        #print(speakers)\n",
    "        #print(s, \"\\n\")\n",
    "        problems[(da3.loc[j, \"document.name\"], da3.loc[j, \"quote.startPosition\"], \n",
    "                  da3.loc[j, \"quote.endPosition\"])] = (da3.loc[j, \"document.plainTextPath\"], \n",
    "                                                       parstart[j], parend[j], speakers.copy())\n",
    "    #else:\n",
    "    #    print(\"[{}] ok\".format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(problems), \"problem quotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "err += \"\\n**** MULTIPLE SPEAKERS ****\\n\\n\"\n",
    "for i, ((doc, qstart, qstop), (path, pstart, pstop, speakers)) in enumerate(problems.items()):\n",
    "    err += \"{}) Document {} [{}:{}], speaker counts = {}\".format(i, doc, qstart, qstop, speakers) + \"\\n\"\n",
    "    err += doctext[path][qstart:qstop] + \"\\n\\n\"\n",
    "    if (qstart, qstop) != (pstart, pstop):\n",
    "        err += \"**context**\\n\"\n",
    "        err += doctext[path][pstart:pstop] + \"\\n\\n\"\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155",
   "metadata": {},
   "source": [
    "Write the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "da3[\"quote.paragraphStartPosition\"] = parstart\n",
    "da3[\"quote.paragraphEndPosition\"] = parend\n",
    "da3[\"quote.paragraphText\"] = par_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will get the first speaker which is usually probably fine (check the above error output if you want)\n",
    "speaker = par_text.str.lower().str.split(\" person \").str[1].str.split(n=1).str[0].fillna(\"-1\")\n",
    "# different documents have different spacing around the \":\", so it's sometimes left trailing by the above\n",
    "speaker = speaker.str.split(\":\").str[0] # probs would have been more efficient to do this first but whatever\n",
    "speaker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = speaker.astype(np.int64)\n",
    "da3[\"quote.speaker\"] = speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 valued speaker is inferred to be the learner (because usually it's a code comment that we assume the learner wrote)\n",
    "da3[\"quote.speakerIsLearner\"] = speaker <= 0\n",
    "da3[\"quote.speakerIsLearner\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160",
   "metadata": {},
   "source": [
    "### Output the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output:\n",
    "    da3.to_csv(os.path.join(outputdir, annotationsfile))\n",
    "    da3.head(20).to_csv(os.path.join(outputdir, sampleannotationsfile)) # for easy visualization on GitHub\n",
    "    \n",
    "    f = open(os.path.join(outputdir, speakererrorsfile), \"w\")\n",
    "    f.write(err)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162",
   "metadata": {},
   "source": [
    "## Consolidate even more even more\n",
    "\n",
    "FIXME BOOKMARK still need to incorporate `Link`s and `Set`s. \n",
    "Also need to take a look at the text files associated with `Code`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('stopping point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv(os.path.join(outputdir, annotationsfile), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"quote.text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168",
   "metadata": {},
   "source": [
    "Get the quote text because Atlas hates me :'("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "170",
   "metadata": {},
   "source": [
    "Getting context for quotes/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 6 #79 #49 #17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = da2.at[idx, \"document.plainTextPath\"].split(\"//\")[1]\n",
    "print(fin)\n",
    "fin = os.path.join(datadir, qdpxdir, inputdocsdir, fin)\n",
    "print(fin)\n",
    "\n",
    "f = open(fin)\n",
    "\n",
    "# source document as a string\n",
    "docstr = f.read()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173",
   "metadata": {},
   "outputs": [],
   "source": [
    "docstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quote start and end\n",
    "start = da2.at[idx, \"quote.startPosition\"]\n",
    "end = da2.at[idx, \"quote.endPosition\"]\n",
    "print(start, \":\", end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quote text\n",
    "quote = docstr[start:end]\n",
    "print(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimal sequence of contiguous full lines containing the quote (start, end, and text)\n",
    "parstart = docstr.rfind(\"\\n\", 0, start) + 1\n",
    "parend = docstr.find(\"\\n\", end)\n",
    "print(parstart, \":\", parend)\n",
    "\n",
    "par = docstr[parstart:parend]\n",
    "print(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parstart (above) splitting the lines into separate list elements\n",
    "fulllines = par.split(\"\\n\")\n",
    "\n",
    "# quote (above) splitting the lines into separate list elements\n",
    "quotelines = quote.split(\"\\n\")\n",
    "\n",
    "display(fulllines)\n",
    "display(quotelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker_old(line):\n",
    "    # line is a code comment or some such\n",
    "    if line[:6] != \"PERSON\":\n",
    "        return None\n",
    "    \n",
    "    ls = line.split(\" : \")\n",
    "    if len(ls) > 0:\n",
    "        ls2 = ls[0].split(\" \")\n",
    "        if len(ls2) > 1:\n",
    "            return int(ls2[1])\n",
    "    \n",
    "    # unknown issue\n",
    "    print(\"UNKNOWN ERROR : get_speaker({})\".format(line))\n",
    "\n",
    "print(get_speaker_old(\"PERSON 0 : or so i should remove or\"))\n",
    "print(get_speaker_old(\"PERSON 1 : (bye)\"))\n",
    "print(get_speaker_old(\"PERSON 1 : \"))\n",
    "print(get_speaker_old(\"    # off by one\"))\n",
    "print(get_speaker_old(\"RETURN : sum of squares of the elements in the matrix\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker(line):\n",
    "    ret = {\"speaker\" : None, \"text\" : None}\n",
    "    # line is a code comment or some such\n",
    "    if line[:7] != \"PERSON \":\n",
    "        ret[\"text\"] = line\n",
    "    else:\n",
    "        try:\n",
    "            ls1 = line.split(\" : \")\n",
    "            ls2 = ls1[0].split(\" \")\n",
    "            ret[\"speaker\"] = int(ls2[1])\n",
    "            ret[\"text\"] = ls1[1]\n",
    "        # line is a code comment or some such, but happened to\n",
    "        # start with the string \"PERSON \" (unlikely)\n",
    "        except IndexError:\n",
    "            print(\"UNKNOWN ERROR : get_speaker({})\".format(line))\n",
    "    \n",
    "    return ret\n",
    "\n",
    "print(get_speaker(\"PERSON 0 : or so i should remove or\"))\n",
    "print(get_speaker(\"PERSON 1 : (bye)\"))\n",
    "print(get_speaker(\"PERSON 1 : \"))\n",
    "print(get_speaker(\"    # off by one\"))\n",
    "print(get_speaker(\"RETURN : sum of squares of the elements in the matrix\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker of each line\n",
    "speakers = [get_speaker(line) for line in fulllines]\n",
    "\n",
    "# quote text of each line\n",
    "quotetextlines = [(line[0] if len(line) < 2 else line[1]) for line in \n",
    "             [line.split(\" : \") for line in quotelines]]\n",
    "\n",
    "# full text of each line\n",
    "fulltextlines = [(line[0] if len(line) < 2 else line[1]) for line in \n",
    "                [line.split(\" : \") for line in fulllines]]\n",
    "\n",
    "print(speakers)\n",
    "print(quotetextlines)\n",
    "print(fulltextlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181",
   "metadata": {},
   "outputs": [],
   "source": [
    "numspeakers = len(set(speakers))\n",
    "print(numspeakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182",
   "metadata": {},
   "outputs": [],
   "source": [
    "if numspeakers == 1:\n",
    "    quotetext = \"\\n\".join(textlines)\n",
    "    print(quotetext)\n",
    "else:\n",
    "    # selectively join things together somehow?\n",
    "    raise Exception(\":)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[newcols] = df.groupby(documentID).transform(f)\n",
    "# pass in a function f that will take in dx (a shorter dataframe where the document is constant) and return an equally-sized dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185",
   "metadata": {},
   "outputs": [],
   "source": [
    "setsDa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(pd.DataFrame.drop)\n",
    "#help(pd.DataFrame.reset_index)\n",
    "help(rfind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(pd.Series.isin)\n",
    "#help(pd.DataFrame.merge)\n",
    "#help(pd.concat)\n",
    "help(pd.DataFrame.applymap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188",
   "metadata": {},
   "source": [
    "# Stuff that didn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189",
   "metadata": {},
   "source": [
    "## First attempt: `portableqda`\n",
    "Doesn't work, feel free to skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/portableqda/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import portableqda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(portableqda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193",
   "metadata": {},
   "source": [
    "## Second attempt: `xml.etree.ElementTree`\n",
    "WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data\"\n",
    "qdpxdir = \"full-project-data\"\n",
    "qdefile = \"project.qde\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = os.path.join(datadir, qdpxdir, qdefile)\n",
    "tree = ET.parse(fin)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199",
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in root:\n",
    "    print(child.tag, \"\\n\\t\", child.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yess you can see the \"plainTextPath\" attribute for each source! now we\n",
    "# know the mapping and don't have to fuck around with bash scripting\n",
    "# things I've forgotten how to do\n",
    "\n",
    "for child in root:\n",
    "    print(child.tag)\n",
    "    for grandchild in child:\n",
    "        print(\"\\t\", grandchild.tag)\n",
    "        print(\"\\t\\t\", grandchild.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Users\n",
    "for child in root[0]:\n",
    "    print(child.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Codebook\n",
    "for child in root[1][0]:\n",
    "    print(child.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing \"only the Sources (annotated documents)\" would give a lot of\n",
    "# output, so instead I'm only doing the first document\n",
    "\n",
    "\"\"\"\n",
    "for child in root[2]:\n",
    "    print(child.attrib)\n",
    "    for grandchild in child:\n",
    "        print(\"\\t\", grandchild.attrib)\n",
    "    print()\n",
    "\"\"\"\n",
    "\n",
    "child = root[2][0]\n",
    "print(child.attrib)\n",
    "for grandchild in child:\n",
    "    print(\"\\t\", grandchild.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the Notes\n",
    "for child in root[3]:\n",
    "    print(child.attrib)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "206",
   "metadata": {},
   "source": [
    "## Third attempt: `pandas`\n",
    "Simply sticking in the whole `.qde` file doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.read_xml(os.path.join(datadir, qdpxdir, qdefile))\n",
    "\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209",
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"User\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210",
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"Codes\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211",
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"TextSource\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in da.columns:\n",
    "    print(col, \"\\t : \", da[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213",
   "metadata": {},
   "source": [
    "## Debugging the extra rows issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc, (quotesDa, quotesDir) in sourcesDir.items():\n",
    "    for quote, codesDa in quotesDir.items():\n",
    "        if quote == \"A1FF467C-2857-4848-A993-5C838B2F6491\":\n",
    "            print(\"doc guid:\", doc)\n",
    "            \n",
    "            print(\"quotes:\")\n",
    "            display(quotesDa)\n",
    "            \n",
    "            print(\"quote:\", quote)\n",
    "            \n",
    "            print(\"codes:\")\n",
    "            display(codesDa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc, (quotesDa, quotesDir) in sourcesDir.items():\n",
    "    for quote, codesDa in quotesDir.items():\n",
    "        if quote == \"B20E50DC-8E26-4552-A0B4-0FBABB45A8E9\":\n",
    "            print(\"doc guid:\", doc)\n",
    "            \n",
    "            print(\"quotes:\")\n",
    "            display(quotesDa)\n",
    "            \n",
    "            print(\"quote:\", quote)\n",
    "            \n",
    "            print(\"codes:\")\n",
    "            display(codesDa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216",
   "metadata": {},
   "source": [
    "As far as I can tell, the orphaned quotes are nowhere in the data at this point. How the fuck are they getting back in?\n",
    "\n",
    "Answer: restarting the kernel fixed the problem smh... still not sure how rerunning cells didn't - might have a hidden bug somewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218",
   "metadata": {},
   "source": [
    "There are 2340 `<Coding>` XML nodes and 2 `<NoteRef>` XML nodes, so something's going on here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([docDir[doc].shape[0] for doc in docDir.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220",
   "metadata": {},
   "source": [
    "So the problem exists prior to merging in the document information from `sourcesDa`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222",
   "metadata": {},
   "source": [
    "So the extra rows are getting some system default initialization for these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#da[da[\"annotation.isCode\"] != True]\n",
    "extraDa = da[~da[\"annotation.isCode\"].isin([True, False])] # \"~\" is negation\n",
    "\n",
    "extraDa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224",
   "metadata": {},
   "source": [
    "So there are 45 such extra rows. Some documents appear more than once, but not all documents appear at all. I could just drop them, but I kind of want to know what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraDa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraDa[[\"quote.guid\", \"quote.name\", \"document.guid\", \"document.name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraDa.to_csv(\"extra_rows.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228",
   "metadata": {},
   "source": [
    "Manual inspection reveals that these are simply quotations with no associated codes. I thought I already removed those - need to go back and double-check that I did it right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S : set of people\n",
    "def eval_q5d(S):\n",
    "    ret = True\n",
    "    for x in S: # forall x\n",
    "        if I(x): # if I(x) then\n",
    "            ret2 = False\n",
    "            for y in S: # there exists a y such that\n",
    "                ret4 = True\n",
    "                for z in S: # forall z\n",
    "                    if z != y: # if z != y then\n",
    "                        ret5 = not F(x, z) or I(z)\n",
    "                    else:\n",
    "                        ret5 = True\n",
    "                    ret4 = ret4 and ret5\n",
    "                ret3 = F(x, y) and not I(y) and ret4\n",
    "                ret2 = ret2 or ret3\n",
    "        else:\n",
    "            # default to True\n",
    "            ret = True\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
